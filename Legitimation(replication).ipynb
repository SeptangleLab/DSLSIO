{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7545649c",
   "metadata": {},
   "source": [
    "# **README.md**\n",
    "This replication package accompanies the term project for the course *Text-as-Data/Natural Language Processing for Political Science* (LMU Munich, SS 2025).  Its purpose is to provide a transparent, modular, and reproducible workflow for computational text analysis in political science. The workflow is structured into **phases**, each producing artifacts consumed by the next, ensuring that every step can be replicated and validated independently. This reproduction was tested to be functional by the three principla investigators: B.A Seohyun Yoon, B.A. Yegor Novikov, and M.A. Borna Ardehi\n",
    "\n",
    "### **Why Phases?**\n",
    "Breaking the pipeline into phases makes the workflow:\n",
    "* **Reproducible** – each step is documented and produces concrete outputs.  \n",
    "* **Auditable** – intermediate data (e.g., metadata, sentence files, gold sets) can be inspected.  \n",
    "* **Modular** – errors or refinements can be addressed at the correct stage without rerunning everything.  \n",
    "* **Extendable** – future researchers can plug in alternative dictionaries, models, or scaling methods.\n",
    "\n",
    "### **5 phases**\n",
    "* **Phase 1:** Converts collected PDFs into clean UTF-8 text and audits coverage.\n",
    "* **Phase 2:** Builds metadata, removes boilerplate, and segments the corpus into analyzable sentences.\n",
    "* **Phase 3:** Constructs and validates dictionaries, then trains and applies supervised classifiers.\n",
    "* **Phase 4:** Implements scaling with seeds and supervised models to measure projection/protection.\n",
    "* **Phase 5:** Produces descriptive statistics and visualizations of legitimation patterns over time and across organizations.\n",
    "\n",
    "---\n",
    "\n",
    "### **Execution Order**\n",
    "`1.0 → 1.1 → 2.0 → 2.1 → 2.2 → 2.3 → 3.0 → 3.1 → 3.2 → 3.3 → 3.4 → 3.5 → 4.0 → 4.1 → 4.2 → 4.3 → 5.0 → 5.1 → 5.2`\n",
    "\n",
    "---\n",
    "\n",
    "### **Technical Requirements**\n",
    "* Python 3.9+; Jupyter Notebook/Lab.  \n",
    "* it is recommended to operate this file in a virtual environment in exact replication of the file.\n",
    "\n",
    "#### **Core packages (pip installations)**\n",
    "* **Data/ML:** pandas, numpy, scipy, scikit-learn, joblib\n",
    "* **Text:** pdfminer.six (PDF → text), spacy, ftfy, chardet\n",
    "* **Progress/CLI:** tqdm, argparse (stdlib)\n",
    "* **Viz:** matplotlib, seaborn\n",
    "\n",
    "##### *Installation*\n",
    "* pip install numpy \n",
    "* pip install pandas \n",
    "* pip install matplotlib \n",
    "* pip install seaborn \n",
    "* pip install scikit-learn\n",
    "* pip install nltk \n",
    "* pip install spacy \n",
    "* pip install gensim \n",
    "* pip install pyreadr \n",
    "* pip install pdfminer.six \n",
    "* pip install jupyter \n",
    "* pip install ipykernel \n",
    "\n",
    "##### *Additional Notes*\n",
    "* nltk and spacy require downloading language models (nltk.download(...), python -m spacy download en_core_web_sm).\n",
    "* gensim is used for embeddings / representation.\n",
    "* pdfminer.six is only needed for the raw text extraction step (Phase 1)\n",
    "* pyreadr is included since some of the data is converted from or to .RData/.sav formats\n",
    "\n",
    "#### **Directory constants to set before running**\n",
    "* input_dir, output_dir for Phase 1.0 conversion.\n",
    "* CORPUS_DIR (and the UTF‑8 mirror path) in Phase 2.0.\n",
    "* BASE paths in plotting cells (Phase 5.1/5.2).\n",
    "\n",
    "#### **Required local files**\n",
    "* **Dictionaries:** norm.txt, funct.txt, proj.txt, prot.txt (2 sets of each)\n",
    "* **Seeds:** 4_projseed.txt, 4_protseed.txt\n",
    "\n",
    "* **Outputs chained across phases:** \n",
    "0_metadata.csv, metadata_bp.csv, 1_sentences.csv, documents.csv, 2_golden_text.csv, 3_pred_documents.csv, 4_PPGS.csv, 4_norm_sentences_pp_SUP.csv, 4_org_year_pp_SUP.csv\n",
    "\n",
    "#### **Hardware:** \n",
    "Standard laptop capacity is sufficient for dictionary and supervised classification tasks; however scaling large corpora may require GPU access. The writing and execution of this code was performed on M4 Macbook Air with 10 GPU.\n",
    "\n",
    "___________________________________________________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa23b661",
   "metadata": {},
   "source": [
    "### **Phase 1.0 — Converting PDF corpus to `.txt` format**\n",
    "\n",
    "This step transforms the manually collected annual-report PDFs into plain UTF-8 text files. It creates a reproducible raw text corpus from which all subsequent preprocessing and analysis phases draw.\n",
    "\n",
    "**Process**\n",
    "\n",
    "* **Imports required tools**\n",
    "  * `os` — for file path handling and directory creation  \n",
    "  * `extract_text` from `pdfminer.high_level` — for extracting text from PDF files (`pip install pdfminer.six`)  \n",
    "\n",
    "* **Defines input and output directories**\n",
    "  * `input_dir` — location of the manually collected PDF corpus files  \n",
    "  * `output_dir` — destination folder for the extracted `.txt` files  \n",
    "\n",
    "* **Ensures output directory exists**\n",
    "  * Creates `output_dir` if it does not already exist  \n",
    "\n",
    "* **Iterates over target years (1975–2025)**\n",
    "  * Constructs expected PDF filename for each year (e.g., `1975_aupcs.pdf`)  \n",
    "  * Checks if the PDF exists in `input_dir`  \n",
    "  * If present:  \n",
    "    – Extracts text from the PDF  \n",
    "    – Writes the extracted text to a `.txt` file in `output_dir`  \n",
    "    – Logs the save action  \n",
    "  * If absent: logs the missing file  \n",
    "\n",
    "* **Manual adjustment note**\n",
    "  * The organisation name in the filename pattern must be edited manually for each dataset  \n",
    "    – e.g., `f\"{year}_NATO.pdf\"` for NATO, `f\"{year}_UNSC.pdf\"` for UNSC  \n",
    "  * Naming of downloaded corpus files follows a uniform structure for consistency  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77844739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "input_dir = '/Users/bornaardehi/Desktop/TAD/Corpus'\n",
    "output_dir = '/Users/bornaardehi/Desktop/TAD/Text_Corpus'\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for year in range(1975, 2026):\n",
    "    filename_pdf = f\"{year}_aupcs.pdf\" # Name changes according to which organization's document is being processed\n",
    "    filepath_pdf = os.path.join(input_dir, filename_pdf)\n",
    "    filepath_txt = os.path.join(output_dir, f\"{year}_aupcs.txt\")\n",
    "\n",
    "    if os.path.exists(filepath_pdf):\n",
    "        print(f\"Processing {filename_pdf}...\")\n",
    "        try:\n",
    "            text = extract_text(filepath_pdf)\n",
    "            with open(filepath_txt, 'w', encoding='utf-8') as f:\n",
    "                f.write(text)\n",
    "            print(f\"Saved {filepath_txt}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename_pdf}: {e}\")\n",
    "    else:\n",
    "        print(f\"Missing: {filename_pdf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41497aa",
   "metadata": {},
   "source": [
    "### **Phase 1.1 — Summarising available `.txt` files and detecting missing years**\n",
    "\n",
    "This step audits the converted text corpus to determine coverage across years and organisations. It produces a tabular overview of available documents and identifies missing years.\n",
    "\n",
    "**Process**\n",
    "\n",
    "* **Imports required tools**\n",
    "  * `os` — for listing and handling file paths  \n",
    "  * `pandas` (`pip install pandas`) — for creating and manipulating tabular data  \n",
    "  * `Path` from `pathlib` — for safer file name parsing  \n",
    "\n",
    "* **Defines key constants**\n",
    "  * `CORPUS_DIR` — directory containing the extracted `.txt` corpus files  \n",
    "  * `YEAR_RANGE` — full set of valid years to check for each organisation (1970–2024 inclusive)  \n",
    "\n",
    "* **Iterates over `.txt` files in the corpus folder**\n",
    "  * Skips any non-`.txt` files  \n",
    "  * Splits the filename into `org` (organisation) and `year` using the last underscore `_` as a separator  \n",
    "  * Validates that `year` is numeric and falls within `YEAR_RANGE`  \n",
    "  * Records organisation–year pairs in a list  \n",
    "\n",
    "* **Creates a DataFrame and summarises coverage**\n",
    "  * Groups data by organisation to calculate:  \n",
    "    – `start_year`: earliest available year  \n",
    "    – `end_year`: latest available year  \n",
    "    – `count`: total number of available years  \n",
    "  * Resets the index for a clean table format  \n",
    "\n",
    "* **Computes missing years per organisation**\n",
    "  * For each organisation, determines which years in `YEAR_RANGE` are absent  \n",
    "  * Stores missing years as a comma-separated list in a new column `missing_years`  \n",
    "\n",
    "* **Reorders and exports the results**\n",
    "  * Keeps columns in the order: `org`, `start_year`, `end_year`, `missing_years`, `count`  \n",
    "  * Saves the summary table as `org_summary.csv` in the working directory  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba2827c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "CORPUS_DIR = \"/Users/bornaardehi/Desktop/TAD/Text_Corpus\"\n",
    "YEAR_RANGE = set(range(1970, 2025))    # inclusive 1970–2024\n",
    "\n",
    "records = []\n",
    "for fname in os.listdir(CORPUS_DIR):\n",
    "    if not fname.lower().endswith(\".txt\"):\n",
    "        continue\n",
    "    stem = Path(fname).stem\n",
    "    if \"_\" not in stem:\n",
    "        continue\n",
    "    org, year_str = stem.rsplit(\"_\", 1)\n",
    "    if not year_str.isdigit():\n",
    "        continue\n",
    "    year = int(year_str)\n",
    "    if year not in YEAR_RANGE:\n",
    "        continue\n",
    "    records.append({\"org\": org, \"year\": year})\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# Summarize findings\n",
    "summary = (\n",
    "    df\n",
    "    .groupby(\"org\")[\"year\"]\n",
    "    .agg([\n",
    "        (\"start_year\", \"min\"),\n",
    "        (\"end_year\",   \"max\"),\n",
    "        (\"count\",      \"size\")\n",
    "    ])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Compute missing years per org\n",
    "def missing_years_list(row):\n",
    "    present = set(df.loc[df.org == row.org, \"year\"])\n",
    "    missing = sorted(YEAR_RANGE - present)\n",
    "    return \",\".join(str(y) for y in missing)\n",
    "\n",
    "summary[\"missing_years\"] = summary.apply(missing_years_list, axis=1)\n",
    "\n",
    "# Reorder columns\n",
    "summary = summary[[\n",
    "    \"org\",\n",
    "    \"start_year\",\n",
    "    \"end_year\",\n",
    "    \"missing_years\",\n",
    "    \"count\"\n",
    "]]\n",
    "\n",
    "# Export to csv\n",
    "out_csv = \"org_summary.csv\"\n",
    "summary.to_csv(out_csv, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdd35c0",
   "metadata": {},
   "source": [
    "### **Extra — Renaming corpus files to enforce uniform naming structure**\n",
    "\n",
    "This auxiliary step standardises the naming convention of extracted text files. It ensures that all corpus files follow a consistent `ORG_YEAR.txt` pattern, which is critical for downstream parsing.\n",
    "\n",
    "**Process**\n",
    "\n",
    "* **Imports required tools**  \n",
    "  * `os` — for interacting with the file system and renaming files  \n",
    "\n",
    "* **Defines working directory**  \n",
    "  * `folder_path` — specifies the location of the extracted `.txt` corpus files  \n",
    "\n",
    "* **Iterates over all files in the target folder**  \n",
    "  * Processes only files ending with `_nato.txt` (case-sensitive)  \n",
    "  * Extracts the `year` by splitting the filename at the underscore `_` and taking the first element  \n",
    "  * Constructs the new filename in the standardised format: `NATO_{year}.txt`  \n",
    "\n",
    "* **Renames files in place**  \n",
    "  * Uses `os.rename()` to change each matching file to the uniform naming convention  \n",
    "  * Prints a log entry showing the original and new file names for verification  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd07ebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "folder_path = '/Users/bornaardehi/Desktop/TAD/Text_Corpus'\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('_nato.txt'):\n",
    "        year = filename.split('_')[0]\n",
    "        new_filename = f'NATO_{year}.txt'\n",
    "        os.rename(\n",
    "            os.path.join(folder_path, filename),\n",
    "            os.path.join(folder_path, new_filename)\n",
    "        )\n",
    "        print(f'Renamed: {filename} -> {new_filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2635216",
   "metadata": {},
   "source": [
    "### **Phase 2.0 — Constructing the metadata / cleaning & audit pipeline**\n",
    "\n",
    "This step builds a comprehensive metadata table for all corpus files while ensuring clean UTF-8 text versions. It validates file integrity, detects encoding issues, and produces both a canonical metadata CSV and a per-organisation coverage summary.\n",
    "\n",
    "**Process**\n",
    "\n",
    "* **Imports required tools**  \n",
    "  * `os`, `hashlib`, `json`, `shutil` — for file system operations, hashing, and file copying  \n",
    "  * `Path` from `pathlib` — for platform-independent file path handling  \n",
    "  * `pandas` (`pip install pandas`) — for tabular metadata storage and export  \n",
    "  * `chardet` (`pip install chardet`) — for detecting unknown file encodings  \n",
    "  * `ftfy` (`pip install ftfy`) — for fixing Unicode anomalies  \n",
    "  * `tqdm` (`pip install tqdm`) — for progress bars during processing  \n",
    "\n",
    "* **Defines constants and directory structure**  \n",
    "  * `CORPUS_DIR` — location of the raw `.txt` corpus files  \n",
    "  * `YEAR_RANGE` — valid year range (1970–2024 inclusive)  \n",
    "  * `PATTERN_SPLIT` — expected filename separator between `<ORG>` and `<YEAR>`  \n",
    "  * `CLEAN_DIR` — UTF-8 mirror directory for cleaned corpus files  \n",
    "  * `META_CSV` — output path for the metadata table  \n",
    "  * `COVERAGE_CSV` — optional per-organisation coverage summary table  \n",
    "  * `LOG_JSON` — JSON file storing rejected files and reasons for audit  \n",
    "\n",
    "* **Creates UTF-8 mirror folder**  \n",
    "  * Ensures `CLEAN_DIR` exists for storing normalised text files  \n",
    "\n",
    "* **Defines helper functions**  \n",
    "  * `sha1_bytes(data)` — generates a SHA-1 hash fingerprint for byte content  \n",
    "  * `read_and_clean(path)` — reads file content, detects encoding if needed, fixes Unicode issues, writes a cleaned UTF-8 version, and returns:  \n",
    "    – clean text  \n",
    "    – original encoding  \n",
    "    – cleaned file path  \n",
    "\n",
    "* **Scans and validates corpus files**  \n",
    "  * Iterates through all `.txt` files recursively in `CORPUS_DIR`  \n",
    "  * Skips files that:  \n",
    "    – contain no `_` in the name  \n",
    "    – have non-numeric or out-of-range years  \n",
    "    – these are logged to `LOG_JSON` as rejects  \n",
    "  * For valid files:  \n",
    "    – Reads and cleans content  \n",
    "    – Stores SHA-1 fingerprint, organisation, year, original/cleaned paths, original encoding, and byte size  \n",
    "\n",
    "* **Builds and exports metadata table**  \n",
    "  * Creates a `pandas` DataFrame, sorted by organisation, year, and original path  \n",
    "  * Saves metadata to `META_CSV`  \n",
    "\n",
    "* **Generates per-organisation coverage summary**  \n",
    "  * Groups by organisation to calculate:  \n",
    "    – `start_year`  \n",
    "    – `end_year`  \n",
    "    – `count` (total documents)  \n",
    "    – `distinct_years`  \n",
    "  * Saves coverage summary to `COVERAGE_CSV`  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d82b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, hashlib, json, shutil\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import chardet, ftfy\n",
    "from tqdm import tqdm        \n",
    "\n",
    "CORPUS_DIR   = Path(\"/Users/bornaardehi/Desktop/TAD/Text_Corpus\")\n",
    "YEAR_RANGE   = set(range(1970, 2025))        # 1970-2024\n",
    "PATTERN_SPLIT = \"_\"                          \n",
    "CLEAN_DIR    = CORPUS_DIR.with_name(CORPUS_DIR.name + \"_utf8\")\n",
    "META_CSV     = \"0_metadata.csv\"              # output path. The naming of the files is the indicator of the steps. Anything prior to creation of metadata is step 0.\n",
    "COVERAGE_CSV = \"org_coverage.csv\"            # summary table\n",
    "LOG_JSON     = \"unparsable_files.json\"       # keeps rejects for extra chek later\n",
    "\n",
    "# utf8 mirror folder\n",
    "CLEAN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "def sha1_bytes(data: bytes) -> str:\n",
    "    return hashlib.sha1(data).hexdigest()\n",
    "def read_and_clean(path: Path):\n",
    "    rel     = path.relative_to(CORPUS_DIR)\n",
    "    outpath = CLEAN_DIR / rel\n",
    "    outpath.parent.mkdir(parents=True, exist_ok=True)\n",
    "    try:\n",
    "        text  = path.read_text(encoding=\"utf-8\")\n",
    "        enc   = \"utf-8\"\n",
    "    except UnicodeDecodeError:\n",
    "        raw   = path.read_bytes()\n",
    "        guess = chardet.detect(raw)\n",
    "        enc   = guess.get(\"encoding\") or \"binary\"\n",
    "        try:\n",
    "            text = raw.decode(enc, errors=\"replace\")\n",
    "        except Exception:\n",
    "            text = raw.decode(\"utf-8\", errors=\"replace\")\n",
    "    text = ftfy.fix_text(text, normalization=\"NFKC\")\n",
    "    outpath.write_text(text, encoding=\"utf-8\")\n",
    "\n",
    "    return text, enc, outpath\n",
    "\n",
    "# Metadata:\n",
    "records, rejects = [], []\n",
    "\n",
    "for path in tqdm(list(CORPUS_DIR.rglob(\"*.txt\")), desc=\"Scanning files\"):\n",
    "    stem = path.stem\n",
    "    if PATTERN_SPLIT not in stem:\n",
    "        rejects.append({\"file\": str(path), \"reason\": \"no '_' found\"})\n",
    "        continue\n",
    "\n",
    "    org, year_str = stem.rsplit(PATTERN_SPLIT, 1)\n",
    "    if not year_str.isdigit():\n",
    "        rejects.append({\"file\": str(path), \"reason\": \"year not numeric\"})\n",
    "        continue\n",
    "\n",
    "    year = int(year_str)\n",
    "    if year not in YEAR_RANGE:\n",
    "        rejects.append({\"file\": str(path), \"reason\": f\"year {year} out of range\"})\n",
    "        continue\n",
    "\n",
    "    text, enc, clean_path = read_and_clean(path)\n",
    "    raw_bytes = text.encode(\"utf-8\")\n",
    "    sha1      = sha1_bytes(raw_bytes)\n",
    "\n",
    "    records.append({\n",
    "        \"doc_id\":       sha1,                      # files' fingerprint\n",
    "        \"org\":          org,\n",
    "        \"year\":         year,\n",
    "        \"orig_path\":    str(path.relative_to(CORPUS_DIR)),\n",
    "        \"clean_path\":   str(clean_path.relative_to(CLEAN_DIR)),\n",
    "        \"orig_encoding\":enc,\n",
    "        \"bytes\":        len(raw_bytes),\n",
    "        \"sha1\":         sha1,\n",
    "    })\n",
    "\n",
    "# Save\n",
    "meta = pd.DataFrame(records).sort_values([\"org\", \"year\", \"orig_path\"])\n",
    "meta.to_csv(META_CSV, index=False)\n",
    "\n",
    "# Table output for perorg coverage\n",
    "coverage = (\n",
    "    meta.groupby(\"org\")[\"year\"]\n",
    "        .agg(start_year=\"min\", end_year=\"max\", count=\"size\",\n",
    "             distinct_years=\"nunique\")\n",
    "        .reset_index()\n",
    ")\n",
    "coverage.to_csv(COVERAGE_CSV, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d881572",
   "metadata": {},
   "source": [
    "### **Phase 2.1 — Boilerplate removal via `0_metadata.csv`**\n",
    "\n",
    "This step strips residual boilerplate text (headers, footers, repeated banners, metadata clutter) from the cleaned UTF-8 corpus.  \n",
    "Because automated detection does not catch every case, manual curation is applied to ensure consistent removal across all files.\n",
    "\n",
    "**Process**\n",
    "\n",
    "* **Imports required tools**  \n",
    "  * `re` — for compiling regular expressions to detect boilerplate patterns  \n",
    "  * `hashlib` — for generating SHA-1 fingerprints of cleaned text  \n",
    "  * `Path` from `pathlib` — for structured file path handling  \n",
    "  * `pandas` (`pip install pandas`) — for reading and writing metadata tables  \n",
    "\n",
    "* **Defines input/output paths**  \n",
    "  * `META_CSV` — metadata file from Phase 2.0 containing UTF-8 corpus info  \n",
    "  * `CLEAN_DIR` — directory with UTF-8 cleaned corpus files  \n",
    "  * `BP_DIR` — new directory for boilerplate-free copies of the cleaned corpus  \n",
    "\n",
    "* **Specifies boilerplate detection rules (RXES)**  \n",
    "  * Dot leaders or page-break garbage  \n",
    "  * All-caps or title-case lines resembling page headers  \n",
    "  * “Table of Contents” or “Contents” lines  \n",
    "  * Copyright / ISBN / ISSN markers  \n",
    "  * Contact details (phone, fax, email, URLs)  \n",
    "  * Standalone bare URLs  \n",
    "  * Isolated numeric page numbers  \n",
    "  * Repeated banners such as “Annual Report” or “REPORT”  \n",
    "\n",
    "* **Defines filter function**  \n",
    "  * `keep(line)` — returns `True` if no boilerplate pattern matches the given line  \n",
    "\n",
    "* **Processes each file from `metadata.csv`**  \n",
    "  * Reads the UTF-8 copy specified in `clean_path`  \n",
    "  * Splits content into lines and removes any matching an RXES pattern  \n",
    "  * Joins the kept lines back into a single cleaned text string  \n",
    "\n",
    "* **Writes boilerplate-free corpus copy**  \n",
    "  * Saves each processed file to `BP_DIR` with identical relative path/filename  \n",
    "  * Ensures subdirectories exist before writing  \n",
    "\n",
    "* **Updates and saves extended metadata**  \n",
    "  * Inherits all columns from `metadata.csv`  \n",
    "  * Adds:  \n",
    "    – `bp_path`: relative path in the boilerplate-free corpus  \n",
    "    – `chars_bp`: character count after boilerplate removal  \n",
    "    – `sha1_bp`: SHA-1 fingerprint of the boilerplate-free text  \n",
    "  * Saves the updated table to `metadata_bp.csv`  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04452cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re, hashlib\n",
    "from pathlib import Path # since we're using path, its important to keep THIS file where the main wd is. we're bypassing input/output\n",
    "import pandas as pd\n",
    "\n",
    "META_CSV   = \"0_metadata.csv\"      # 0_ naming is a reference to keep track of the stage in dataset development                     \n",
    "CLEAN_DIR  = Path(\"/Users/bornaardehi/Desktop/TAD/Text_Corpus_utf8\")\n",
    "BP_DIR     = CLEAN_DIR.with_name(CLEAN_DIR.name + \"_nobp\") \n",
    "BP_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "RXES = [\n",
    "    # (1) dots / page-break \n",
    "    re.compile(r'^[\\s\\.]{7,}$'),\n",
    "    # (2) ALL-CAP or Title-Case lines that look like page headers\n",
    "    re.compile(r'^[A-ZÁÉÍÓÚÜÑ0-9 ,;\\'\\-/]{10,}$'), # some files were titled as such. this seleciton was made after going through what we had\n",
    "    # (3) “Table of Contents” & variants\n",
    "    re.compile(r'^\\s*(TABLE OF CONTENTS|CONTENTS)\\s*$', re.I),\n",
    "    # (4) copyright / ISBN / ISSN / © lines\n",
    "    re.compile(r'^\\s*[©]\\s*'),\n",
    "    re.compile(r'^\\s*ISBN\\b',  re.I),\n",
    "    re.compile(r'^\\s*ISSN\\b',  re.I),\n",
    "    # (5) contact blocks (Tel, Fax, E-mail, URL)\n",
    "    re.compile(r'^\\s*(Tel|Telephone|Fax|E-?mail|URL)\\b', re.I),\n",
    "    # (6) URLs\n",
    "    re.compile(r'^\\s*https?://', re.I),\n",
    "    # (7) single line page numbers\n",
    "    re.compile(r'^\\s*\\d{1,4}\\s*$'),\n",
    "    # (8) repeated “Annual Report” / “REPORT” banners\n",
    "    re.compile(r'^\\s*(ANNUAL\\s+REPORT|REPORT)\\s*$', re.I),\n",
    "]\n",
    "\n",
    "def keep(line: str) -> bool:\n",
    "    \"\"\"Return True if the line should be kept (i.e. not boiler-plate).\"\"\"\n",
    "    return not any(rx.search(line) for rx in RXES)\n",
    "\n",
    "sha1 = lambda s: hashlib.sha1(s.encode()).hexdigest()\n",
    "\n",
    "meta = pd.read_csv(META_CSV)\n",
    "out_rows = []\n",
    "\n",
    "for _, row in meta.iterrows():\n",
    "    in_path  = CLEAN_DIR / row.clean_path\n",
    "    raw_lines = in_path.read_text(encoding=\"utf-8\", errors=\"ignore\").splitlines()\n",
    "\n",
    "    kept_lines = [ln for ln in raw_lines if keep(ln)]\n",
    "    cleaned    = \"\\n\".join(kept_lines).strip()\n",
    "\n",
    "    bp_relpath = Path(row.clean_path)\n",
    "    out_path   = BP_DIR / bp_relpath\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    out_path.write_text(cleaned, encoding=\"utf-8\")\n",
    "\n",
    "    out_rows.append({\n",
    "        **row,\n",
    "        \"bp_path\":  str(bp_relpath),\n",
    "        \"chars_bp\": len(cleaned),\n",
    "        \"sha1_bp\":  sha1(cleaned),\n",
    "    })\n",
    "\n",
    "pd.DataFrame(out_rows).to_csv(\"metadata_bp.csv\", index=False) # this file was later removed as we had to perform manual clean up and discarded this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc08e760",
   "metadata": {},
   "source": [
    "### **Phase 2.2 — Segmenting corpus into sentences**\n",
    "\n",
    "This step splits the cleaned corpus into individual sentences. It ensures that each sentence is stored as a separate unit, enabling precise downstream classification, scaling, and statistical analysis.\n",
    "\n",
    "**Process**\n",
    "\n",
    "* **Imports required tools**  \n",
    "  * `re` — for pre-sentencization text repairs (hyphenation, spacing)  \n",
    "  * `Path` from `pathlib` — for file path handling  \n",
    "  * `pandas` (`pip install pandas`) — for metadata loading and sentence table output  \n",
    "  * `spacy` (`pip install spacy`; download model with `python -m spacy download en_core_web_sm`) — for NLP-based sentence splitting  \n",
    "  * `tqdm` (`pip install tqdm`) — for progress tracking  \n",
    "\n",
    "* **Defines configuration variables**  \n",
    "  * `META_CSV` — metadata file from Phase 2.0 containing cleaned UTF-8 file paths  \n",
    "  * `UTF8_DIR` — folder containing UTF-8 cleaned corpus files  \n",
    "  * `OUT_CSV` — output file for sentence-level corpus  \n",
    "\n",
    "* **Initialises spaCy with sentencizer only**  \n",
    "  * Loads `en_core_web_sm` with all heavy components disabled (no POS tagging, parsing, NER) for speed  \n",
    "  * Adds `sentencizer` pipeline component if missing  \n",
    "  * Sets initial `nlp.max_length` to 3 million characters (adjustable per document)  \n",
    "\n",
    "* **Compiles regex patterns for text repair**  \n",
    "  * `RE_LINE_HYPHEN`: joins words split across lines (`inter-\\naction → interaction`)  \n",
    "  * `RE_NEWLINES`: replaces newlines with spaces  \n",
    "  * `RE_POLICY_HYPHEN`: preserves compound policy terms by replacing hyphen with underscore (`peace-building → peace_building`)  \n",
    "  * `RE_SPACES`: collapses multiple spaces into one  \n",
    "\n",
    "* **Defines repair function**  \n",
    "  * `repair_text(txt)` applies the regex patterns in sequence  \n",
    "  * Converts text to lowercase and strips whitespace  \n",
    "\n",
    "* **Iterates through corpus metadata**  \n",
    "  * Reads each UTF-8 cleaned file based on `clean_path`  \n",
    "  * Applies `repair_text()` to prepare content for segmentation  \n",
    "  * Dynamically increases `nlp.max_length` if document exceeds current limit  \n",
    "  * Uses spaCy to split text into sentences  \n",
    "\n",
    "* **Collects sentence-level data**  \n",
    "  * Skips empty sentences  \n",
    "  * For each sentence, records:  \n",
    "    – `doc_id` (hash from Phase 2.0)  \n",
    "    – `org` (organisation)  \n",
    "    – `year` (document year)  \n",
    "    – `sent_id` (sentence number within doc)  \n",
    "    – `sentence` (clean sentence text)  \n",
    "\n",
    "* **Saves output**  \n",
    "  * Exports all sentence records to `sentences.csv` for downstream analysis  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09e46d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "\n",
    "META_CSV   = \"0_metadata.csv\"                            # produced earlier\n",
    "UTF8_DIR   = Path(\"/Users/bornaardehi/Desktop/TAD/Text_Corpus_utf8\")\n",
    "OUT_CSV    = \"1_sentences.csv\"                           # final output (there is one more iteration after this in the next step)\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\",\n",
    "                 disable=[\"tagger\", \"parser\", \"attribute_ruler\",\n",
    "                          \"lemmatizer\", \"ner\"])\n",
    "if not nlp.has_pipe(\"sentencizer\"):\n",
    "    nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "nlp.max_length = 3_000_000\n",
    "\n",
    "# REGEXES \n",
    "RE_LINE_HYPHEN   = re.compile(r\"-\\s*\\n\\s*\")\n",
    "RE_NEWLINES      = re.compile(r\"\\s*\\n\\s*\")\n",
    "RE_POLICY_HYPHEN = re.compile(r\"(\\b\\w+)-(\\w+\\b)\")\n",
    "RE_SPACES        = re.compile(r\"\\s{2,}\")\n",
    "\n",
    "def repair_text(txt: str) -> str:\n",
    "    txt = RE_LINE_HYPHEN.sub(\"\", txt)\n",
    "    txt = RE_NEWLINES.sub(\" \", txt)\n",
    "    txt = RE_POLICY_HYPHEN.sub(r\"\\1_\\2\", txt)\n",
    "    txt = RE_SPACES.sub(\" \", txt)\n",
    "    return txt.lower().strip()\n",
    "\n",
    "meta = pd.read_csv(META_CSV)\n",
    "\n",
    "rows = []\n",
    "for _, m in tqdm(meta.iterrows(), total=len(meta), desc=\"Sentence splitting\"):\n",
    "    path = UTF8_DIR / m[\"clean_path\"]\n",
    "    text = path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "    text = repair_text(text)\n",
    "    if len(text) >= nlp.max_length:\n",
    "        nlp.max_length = len(text) + 1\n",
    "\n",
    "    doc = nlp(text)\n",
    "\n",
    "    for sid, sent in enumerate(doc.sents, start=1):\n",
    "        sent_txt = sent.text.strip()\n",
    "        if not sent_txt:\n",
    "            continue\n",
    "        rows.append({\n",
    "            \"doc_id\":   m[\"doc_id\"],\n",
    "            \"org\":      m[\"org\"],\n",
    "            \"year\":     m[\"year\"],\n",
    "            \"sent_id\":  sid,\n",
    "            \"sentence\": sent_txt\n",
    "        })\n",
    "\n",
    "pd.DataFrame(rows).to_csv(OUT_CSV, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d18be5b",
   "metadata": {},
   "source": [
    "### **Phase 2.3 — Re-running preprocessing to produce a cleaner sentence DataFrame**\n",
    "\n",
    "This step refines the sentence-level corpus by removing OCR artifacts, enumeration tokens, and underspecified text fragments. The result is the `1_documents.csv` file that serves as the working dataset for supervised and scaling phases.\n",
    "\n",
    "**Process**\n",
    "\n",
    "* **Imports required tools**  \n",
    "  * `re` — for advanced text cleaning with regular expressions  \n",
    "  * `pandas` (`pip install pandas`) — for loading and saving CSV files  \n",
    "\n",
    "* **Defines input/output paths**  \n",
    "  * `IN_CSV` — the sentence-level corpus produced in Phase 2.2 (`1_sentences.csv`)  \n",
    "  * `OUT_CSV` — the cleaned output file containing only well-formed sentences (`1_documents.csv`)  \n",
    "\n",
    "* **Compiles regex patterns**  \n",
    "  * `RE_SPACED`: detects OCR drift patterns where letters are spaced individually (`t h e p r o j e c t`)  \n",
    "  * `RE_ENUM`: matches enumeration markers such as `1.`, `6.2.1.`, or `b.` at the start of a token  \n",
    "\n",
    "* **Defines helper functions**  \n",
    "  * `collapse(match)` — removes spaces from spaced-letter OCR fragments  \n",
    "  * `clean_sentence(text)` — applies multiple cleaning rules:  \n",
    "    – Collapses spaced letters  \n",
    "    – Removes enumeration tokens and single-character tokens  \n",
    "    – Collapses multiple spaces to one  \n",
    "    – Requires at least 4 alphabetic words (each ≥ 2 letters) for a sentence to be kept; otherwise returns an empty string  \n",
    "\n",
    "* **Processes sentence-level corpus**  \n",
    "  * Loads `1_sentences.csv` as a DataFrame (all columns read as strings)  \n",
    "  * Applies `clean_sentence()` to each sentence  \n",
    "  * Drops any sentences reduced to empty strings after cleaning  \n",
    "\n",
    "* **Saves cleaned output**  \n",
    "  * Writes the cleaned DataFrame to `documents.csv` for downstream analysis  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c410aaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, pandas as pd\n",
    "\n",
    "IN_CSV  = \"1_sentences.csv\"           # from last step, as mentioned, we reproduced an alternative after manual boilerplate removal of all documents.\n",
    "OUT_CSV = \"1_documents.csv\"           # the final metadata for replciaiton, after multiple clean up iterations\n",
    "\n",
    "# regexes \n",
    "# spaced OCR drift: sequence of single letters separated by spaces\n",
    "RE_SPACED = re.compile(r'(?:\\b[a-zA-Z]\\s+){2,}[a-zA-Z]\\b') # based on the cases we noticed requiring removal\n",
    "# enumeration tokens:  1.   6.2.1.   b.\n",
    "RE_ENUM = re.compile(r'^([a-zA-Z]|\\d+)(?:\\.(?:[a-zA-Z]|\\d+))*\\.?$') # also based on the cases we noticed requiring removal\n",
    "\n",
    "def collapse(match):\n",
    "    \"\"\"Remove spaces in spaced-letter chunk.\"\"\"\n",
    "    return match.group(0).replace(\" \", \"\")\n",
    "\n",
    "def clean_sentence(text: str) -> str:\n",
    "    # 1) collapse spaced letters\n",
    "    text = RE_SPACED.sub(collapse, text)\n",
    "\n",
    "    # 2) remove enumeration tokens & 1-letter tokens\n",
    "    tokens = [t for t in text.split() if not RE_ENUM.match(t) and len(t) > 1]\n",
    "    if not tokens:\n",
    "        return \"\"\n",
    "\n",
    "    text = \" \".join(tokens)\n",
    "    text = re.sub(r'\\s{2,}', ' ', text).strip()\n",
    "\n",
    "    # 3) require at least 4 alphabetic words (length ≥2)\n",
    "    alpha_words = re.findall(r'[a-zA-Z]{2,}', text)\n",
    "    if len(alpha_words) < 4:\n",
    "        return \"\"\n",
    "\n",
    "    return text\n",
    "\n",
    "df = pd.read_csv(IN_CSV, dtype=str)\n",
    "df[\"sentence\"] = df[\"sentence\"].apply(clean_sentence)\n",
    "df = df[df[\"sentence\"].str.len() > 0]\n",
    "\n",
    "df.to_csv(OUT_CSV, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7be9172",
   "metadata": {},
   "source": [
    "### **Phase 2.3 –– Dictionary construction**\n",
    "We built the dictionaries for the supervised dictionary SVM method. called dict_v1. It included four dictionaries for: normative, functional, projection and protection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6ba345",
   "metadata": {},
   "source": [
    "### **Phase 3.1 — Stratified sampling for initial dictionary-based manual labelling**\n",
    "\n",
    "This phase serves as the bridge between preprocessing and supervised model training. It draws a stratified sample of sentences to be manually coded, creating the initial gold-standard dataset for validating and refining dictionaries.\n",
    "\n",
    "**Process**\n",
    "\n",
    "* **Imports required tools**  \n",
    "  * `pandas` (`pip install pandas`) — for data handling and CSV I/O  \n",
    "  * `numpy` (`pip install numpy`) — for numerical operations and rounding  \n",
    "  * `Path` from `pathlib` — for file path management (not essential here, but consistent with workflow)  \n",
    "\n",
    "* **Defines configuration variables**  \n",
    "  * `SENT_FILE` — cleaned, sentence-level dataset from Phase 2.3 (`documents.csv`)  \n",
    "  * `TOTAL_SAMPLE` — total number of sentences to sample (15,000)  \n",
    "  * `PER_CODER` — number of sentences assigned to each coder (5,000)  \n",
    "  * `CODER_IDS` — list of unique identifiers for coders: `SH` (Seohyun), `YN` (Yegor), `BA` (Borna)  \n",
    "  * `RANDOM_STATE` — fixed seed for reproducibility of sampling  \n",
    "\n",
    "* **Loads dataset and defines strata**  \n",
    "  * Reads `documents.csv` into a DataFrame  \n",
    "  * Creates a `decade` column from `year` for stratification (e.g., `1983 → 1980`)  \n",
    "  * Groups data into strata by `org` and `decade`  \n",
    "\n",
    "* **Performs stratified sampling**  \n",
    "  * For each `(org, decade)` group, calculates proportional sample size relative to dataset share  \n",
    "  * Ensures sample size does not exceed group size  \n",
    "  * Samples rows from each group using fixed random seed  \n",
    "  * Concatenates all strata samples into one DataFrame, shuffles once, and resets index  \n",
    "  * If total exceeds `TOTAL_SAMPLE`, down-samples to exactly that size  \n",
    "\n",
    "* **Splits sample into coder-specific files**  \n",
    "  * Divides sampled DataFrame into consecutive blocks of `PER_CODER` rows  \n",
    "  * Adds an empty `label` column after the sentence column for coders to fill  \n",
    "  * Writes each block to a separate file: `{CODER_ID}_to_label.csv`  \n",
    "  * Logs the number of rows in each output file  \n",
    "\n",
    "* **Outcome**  \n",
    "  * Three CSV files generated:  \n",
    "    – `SH_to_label.csv`  \n",
    "    – `YN_to_label.csv`  \n",
    "    – `BA_to_label.csv`  \n",
    "  * Each file contains 5,000 randomly selected, stratified sentences, ready for human coding in the first iteration  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e45cb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "SENT_FILE      = \"1_documents.csv\"\n",
    "TOTAL_SAMPLE   = 15_000 # choesn based on recommendations from the slides, to utilize at least 5% of the total corpus for training\n",
    "PER_CODER      = 5_000\n",
    "CODER_IDS      = [\"SH\", \"YN\", \"BA\"] # three PIs\n",
    "RANDOM_STATE   = 42                   # reproducible\n",
    "\n",
    "sent = pd.read_csv(SENT_FILE)\n",
    "sent[\"decade\"] = (sent[\"year\"] // 10) * 10      # 1970→1970, 1983→1980…\n",
    "strata = sent.groupby([\"org\", \"decade\"])\n",
    "\n",
    "# stratified sampling is essentially randomised, which allows for greater empirical access to variety of sentences we're training on \n",
    "samples = []\n",
    "for _, group in strata:\n",
    "    # proportional allocation\n",
    "    n = int(np.round(len(group) / len(sent) * TOTAL_SAMPLE))\n",
    "    n = min(n, len(group))\n",
    "    if n > 0:\n",
    "        samples.append(group.sample(n=n, random_state=RANDOM_STATE))\n",
    "\n",
    "sampled = (pd.concat(samples)\n",
    "             .sample(frac=1, random_state=RANDOM_STATE)   # shuffle once\n",
    "             .reset_index(drop=True))\n",
    "\n",
    "# exactly TOTAL_SAMPLE rows\n",
    "if len(sampled) > TOTAL_SAMPLE:\n",
    "    sampled = sampled.sample(n=TOTAL_SAMPLE, random_state=RANDOM_STATE).reset_index(drop=True)\n",
    "\n",
    "# split into coder files \n",
    "for i, coder in enumerate(CODER_IDS):\n",
    "    start = i * PER_CODER\n",
    "    end   = start + PER_CODER\n",
    "    part  = sampled.iloc[start:end].copy()\n",
    "    part.insert(part.columns.get_loc(\"sentence\") + 1, \"label\", \"\")  # blank label col\n",
    "    outfile = f\"{coder}_to_label.csv\"\n",
    "    part.to_csv(outfile, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f2c5b4",
   "metadata": {},
   "source": [
    "### **Phase 3.2 — Second iteration: computer-assisted labelling with updated dictionaries**\n",
    "\n",
    "In this iteration, the term dictionaries (`funct.txt`, `norm.txt`, `proj.txt`, `prot.txt`) were manually revised before use.  \n",
    "Some words were **ablated (removed)** due to high false-positive rates in Phase 3.1, often because of polysemy (same term used in unrelated contexts) or excessive overmatching that created noise in coder workload.  \n",
    "\n",
    "This phase reduces manual labelling burden by pre-filtering the corpus with a tuned dictionary, ensuring coders see only sentences likely relevant to the classification task, while balancing coverage across organisations and decades.\n",
    "\n",
    "**Process**\n",
    "\n",
    "* **Imports required tools**  \n",
    "  * `pandas` (`pip install pandas`) — for corpus handling and sampling  \n",
    "  * `numpy` (`pip install numpy`) — for proportional allocation  \n",
    "  * `re` — for token pattern matching  \n",
    "  * `sys` — for clean script exits on validation errors  \n",
    "  * `Path` from `pathlib` — for file path handling  \n",
    "\n",
    "* **Defines key file paths**  \n",
    "  * `DOC_CSV` — cleaned sentence-level corpus from Phase 2.3 (`1_documents.csv`)  \n",
    "  * `DICT_DIR` — directory containing revised dictionary files  \n",
    "  * `OUT_GOLD` — output file for the 15,000-sentence gold sample (`virgin_text.csv`)  \n",
    "  * `CODERS` — list of human coders: `SH`, `BA`, `YN`  \n",
    "\n",
    "* **Loads and validates corpus**  \n",
    "  * Ensures `documents.csv` contains required columns: `doc_id`, `org`, `year`, `sent_id`, `sentence`  \n",
    "  * Drops empty or whitespace-only sentences  \n",
    "\n",
    "* **Loads dictionaries**  \n",
    "  * Reads each dictionary file into a set of lowercase terms, skipping blanks  \n",
    "  * Validates that all dictionary files exist before proceeding  \n",
    "\n",
    "* **Flags sentences containing dictionary terms**  \n",
    "  * Tokenises each sentence into lowercase words  \n",
    "  * For each dictionary, creates a binary flag (1 if at least one term present, else 0)  \n",
    "  * Appends these flags as new columns in the DataFrame  \n",
    "\n",
    "* **Filters corpus to relevant sentences**  \n",
    "  * Retains only sentences containing ≥1 dictionary term across all four dictionaries  \n",
    "  * Validates that enough candidates exist to build a 15,000-sentence sample  \n",
    "\n",
    "* **Draws stratified sample**  \n",
    "  * Creates decade strata from `year` and groups by `(org, decade)`  \n",
    "  * Allocates sample size proportionally to each stratum’s share of the filtered corpus  \n",
    "  * Adjusts for overshoot (random down-sample) or undershoot (fills from remainder pool)  \n",
    "\n",
    "* **Saves the gold sample**  \n",
    "  * Writes the final stratified 15,000-sentence sample to `virgin_text.csv`  \n",
    "\n",
    "* **Prepares coder verification files**  \n",
    "  * Shuffles the gold sample  \n",
    "  * Splits into three equal chunks of 5,000 sentences each  \n",
    "  * Inserts an empty `label` column after the sentence column  \n",
    "  * Saves each chunk as `verify_{CODER}.csv` for manual verification  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e552ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, re, sys\n",
    "from pathlib import Path\n",
    "\n",
    "BASE      = Path(__file__).resolve().parent        \n",
    "DOC_CSV   = BASE / \"documents.csv\"\n",
    "DICT_DIR  = BASE / \"dict_v1\"                           # contains the four initial dictionaries\n",
    "OUT_GOLD  = BASE / \"virgin_text.csv\"\n",
    "CODERS    = [\"SH\", \"BA\", \"YN\"]\n",
    "\n",
    "df = pd.read_csv(DOC_CSV)\n",
    "\n",
    "# ensure mandatory cols exist\n",
    "req_cols = {\"doc_id\", \"org\", \"year\", \"sent_id\", \"sentence\"}\n",
    "if not req_cols.issubset(df.columns):\n",
    "    sys.exit(f\"✗ {DOC_CSV} must contain columns: {', '.join(sorted(req_cols))}\")\n",
    "\n",
    "# drop whitespace sentences\n",
    "df[\"sentence\"] = df[\"sentence\"].fillna(\"\").astype(str)\n",
    "df = df[df[\"sentence\"].str.strip().astype(bool)]\n",
    "\n",
    "DICT_FILES = {\"funct\": \"funct.txt\",\n",
    "              \"norm\":  \"norm.txt\",\n",
    "              \"proj\":  \"proj.txt\",\n",
    "              \"prot\":  \"prot.txt\"}\n",
    "\n",
    "DICTS = {}\n",
    "for key, fname in DICT_FILES.items():\n",
    "    fpath = DICT_DIR / fname\n",
    "    if not fpath.exists():\n",
    "        sys.exit(f\"✗ dictionary file missing: {fpath}\")\n",
    "    DICTS[key] = {ln.strip().lower() for ln in fpath.open(encoding=\"utf-8\")\n",
    "                  if ln.strip()}\n",
    "\n",
    "tok_pat = re.compile(r\"\\b\\w+\\b\")\n",
    "\n",
    "def flag_row(text: str):\n",
    "    toks = tok_pat.findall(text.lower())\n",
    "    return {k: int(any(t in vocab for t in toks)) for k, vocab in DICTS.items()}\n",
    "\n",
    "flags_df = df[\"sentence\"].apply(flag_row).apply(pd.Series)\n",
    "df = pd.concat([df, flags_df], axis=1)\n",
    "\n",
    "df = df[df[list(DICT_FILES)].sum(axis=1) > 0]\n",
    "\n",
    "if len(df) < 15_000:\n",
    "    sys.exit(\"✗ Not enough labelled sentences to reach 15 000\")\n",
    "\n",
    "# STRATIFIED 15 000-ROW SAMPLE\n",
    "df[\"decade\"] = (df[\"year\"] // 10) * 10\n",
    "strata = df.groupby([\"org\", \"decade\"])\n",
    "\n",
    "target = 15_000\n",
    "rows = []\n",
    "\n",
    "for _, grp in strata:\n",
    "    # proportional allocation\n",
    "    n = int(round(len(grp) / len(df) * target))\n",
    "    n = min(n, len(grp))\n",
    "    if n:\n",
    "        rows.append(grp.sample(n=n, random_state=42))\n",
    "\n",
    "sample = pd.concat(rows).reset_index(drop=True)\n",
    "\n",
    "# adjust if overshoot / undershoot\n",
    "if len(sample) > target:\n",
    "    sample = sample.sample(n=target, random_state=42)\n",
    "elif len(sample) < target:\n",
    "    # randomly add extra rows from remaining pool\n",
    "    remainder = df.drop(sample.index)\n",
    "    extra = remainder.sample(n=target - len(sample), random_state=42)\n",
    "    sample = pd.concat([sample, extra]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "sample.to_csv(OUT_GOLD, index=False)\n",
    "\n",
    "sample_shuffled = sample.sample(frac=1, random_state=99).reset_index(drop=True)\n",
    "chunk = 5_000\n",
    "\n",
    "for i, coder in enumerate(CODERS):\n",
    "    part = sample_shuffled.iloc[i*chunk:(i+1)*chunk].copy()\n",
    "    part.insert(part.columns.get_loc(\"sentence\") + 1, \"label\", \"\")   # blank label\n",
    "    out = BASE / f\"verify_{coder}.csv\"\n",
    "    part.to_csv(out, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717ef2a2",
   "metadata": {},
   "source": [
    "### **Phase 3.3 — Third iteration: reduced dictionary size and refined subset selection**\n",
    "\n",
    "In this iteration, the dictionaries were deliberately reduced to remove marginal, ambiguous, or low-precision terms that inflated earlier samples with irrelevant content.  \n",
    "Only **two categories** were retained — **functional (`funct.txt`)** and **normative (`norm.txt`)** — simplifying classification and improving coder efficiency.  \n",
    "\n",
    "**Process**\n",
    "\n",
    "* **Imports required tools**  \n",
    "  * `pandas` (`pip install pandas`) — for dataset manipulation and CSV export  \n",
    "  * `numpy` (`pip install numpy`) — for proportional sampling calculations  \n",
    "  * `re` — for tokenisation  \n",
    "  * `sys` — for clean exits on missing files or validation errors  \n",
    "  * `Path` from `pathlib` — for structured file path handling  \n",
    "\n",
    "* **Defines file paths**  \n",
    "  * `DOC_CSV` — cleaned sentence-level corpus from Phase 2.3 (`documents.csv`)  \n",
    "  * `DICT_DIR` — directory containing reduced dictionaries (`funct.txt`, `norm.txt`)  \n",
    "  * `OUT_CSV` — output file for the final refined sample (`golden_text.csv`)  \n",
    "\n",
    "* **Loads and validates corpus**  \n",
    "  * Ensures `documents.csv` exists and contains required columns: `doc_id`, `org`, `year`, `sent_id`, `sentence`  \n",
    "  * Removes empty or whitespace-only sentences  \n",
    "\n",
    "* **Loads reduced dictionaries**  \n",
    "  * `load_dict(name)` — reads a dictionary file into a lowercase term set, skipping blanks  \n",
    "  * Loads `vocab_funct` and `vocab_norm`  \n",
    "\n",
    "* **Flags and labels sentences**  \n",
    "  * Tokenises each sentence into lowercase words  \n",
    "  * Flags **functional** and **normative** matches separately  \n",
    "  * Assigns label:  \n",
    "    – `\"funct\"` if only functional terms matched  \n",
    "    – `\"norm\"` if only normative terms matched  \n",
    "    – `\"x\"` if both categories matched  \n",
    "    – `\"?\"` if no match  \n",
    "  * Retains only sentences with labels `\"funct\"`, `\"norm\"`, or `\"x\"`  \n",
    "\n",
    "* **Draws stratified sample**  \n",
    "  * Groups valid sentences by `(org, decade)`  \n",
    "  * Allocates sample size proportionally to each stratum’s share of the valid corpus  \n",
    "  * Ensures each stratum sample does not exceed available rows  \n",
    "  * Concatenates strata, then trims or tops up to exactly **10,000 sentences**  \n",
    "\n",
    "* **Exports refined dataset**  \n",
    "  * Saves the stratified **10,000-sentence sample** to `golden_text.csv` for final analysis or coder verification  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5582c8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, re, sys\n",
    "from pathlib import Path\n",
    "\n",
    "BASE       = Path(__file__).resolve().parent        \n",
    "DOC_CSV    = BASE / \"documents.csv\"\n",
    "DICT_DIR   = BASE / \"dict_V2\"                        # second dictionary\n",
    "OUT_CSV    = BASE / \"golden_text.csv\"\n",
    "\n",
    "if not DOC_CSV.exists():\n",
    "    sys.exit(f\"✗ {DOC_CSV} missing\")\n",
    "\n",
    "df = pd.read_csv(DOC_CSV)\n",
    "needed = {\"doc_id\",\"org\",\"year\",\"sent_id\",\"sentence\"}\n",
    "if not needed.issubset(df.columns):\n",
    "    sys.exit(f\"✗ {DOC_CSV} must contain columns: {', '.join(sorted(needed))}\")\n",
    "\n",
    "df[\"sentence\"] = df[\"sentence\"].fillna(\"\").astype(str)\n",
    "df = df[df[\"sentence\"].str.strip().astype(bool)]\n",
    "\n",
    "def load_dict(name):\n",
    "    f = DICT_DIR / f\"{name}.txt\"\n",
    "    if not f.exists():\n",
    "        sys.exit(f\"✗ dictionary file missing: {f}\")\n",
    "    return {ln.strip().lower() for ln in f.open(encoding=\"utf-8\") if ln.strip()}\n",
    "\n",
    "vocab_funct = load_dict(\"funct\")\n",
    "vocab_norm  = load_dict(\"norm\")\n",
    "\n",
    "token_pat = re.compile(r\"\\b\\w+\\b\")\n",
    "\n",
    "def flag_row(text):\n",
    "    toks = token_pat.findall(text.lower())\n",
    "    fc = int(any(t in vocab_funct for t in toks))\n",
    "    nc = int(any(t in vocab_norm  for t in toks))\n",
    "    if fc and not nc:\n",
    "        lbl = \"funct\"\n",
    "    elif nc and not fc:\n",
    "        lbl = \"norm\"\n",
    "    elif fc and nc:\n",
    "        lbl = \"x\"\n",
    "    else:\n",
    "        lbl = \"?\"\n",
    "    return fc, nc, lbl\n",
    "\n",
    "flags = df[\"sentence\"].apply(flag_row).tolist()\n",
    "df[[\"funct\",\"norm\",\"label\"]] = pd.DataFrame(flags, index=df.index)\n",
    "\n",
    "df_valid = df[df[\"label\"] != \"?\"].reset_index(drop=True)\n",
    "if len(df_valid) < 10000:\n",
    "    sys.exit(\"✗ Not enough labelled sentences to reach 10000 rows.\")\n",
    "df_valid[\"decade\"] = (df_valid[\"year\"] // 10) * 10\n",
    "strata = df_valid.groupby([\"org\",\"decade\"])\n",
    "\n",
    "target = 10000\n",
    "rows = []\n",
    "for _, grp in strata:\n",
    "    n = int(round(len(grp) / len(df_valid) * target))\n",
    "    n = min(n, len(grp))\n",
    "    if n:\n",
    "        rows.append(grp.sample(n=n, random_state=7))\n",
    "\n",
    "sample = pd.concat(rows).reset_index(drop=True)\n",
    "\n",
    "if len(sample) > target:\n",
    "    sample = sample.sample(n=target, random_state=7).reset_index(drop=True)\n",
    "elif len(sample) < target:\n",
    "    extra = (df_valid\n",
    "             .drop(sample.index)\n",
    "             .sample(n=target - len(sample), random_state=7))\n",
    "    sample = pd.concat([sample, extra]).reset_index(drop=True)\n",
    "\n",
    "assert len(sample) == 10000, \"Sample is not 100 rows!\"\n",
    "\n",
    "# ── 5. EXPORT -------------------------------------------------\n",
    "sample.to_csv(OUT_CSV, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25db1c03",
   "metadata": {},
   "source": [
    "### **Phase 3.4 — Supervised classification: functional vs normative + Model and Vector trainer**\n",
    "\n",
    "This phase uses the refined **10,000-row golden dataset** from Phase 3.3 to train and validate a binary classifier distinguishing **functional** from **normative** sentences.  \n",
    "Dictionary matches are included as explicit features alongside TF–IDF vectors to boost interpretability and performance.\n",
    "\n",
    "**Process**\n",
    "\n",
    "* **Imports required tools**  \n",
    "  * `re` — for tokenisation and dictionary matching  \n",
    "  * `joblib` (`pip install joblib`) — for saving trained models  \n",
    "  * `Path` from `pathlib` — for file path handling  \n",
    "  * `numpy` (`pip install numpy`) — for numeric array handling  \n",
    "  * `pandas` (`pip install pandas`) — for dataset handling  \n",
    "  * `scipy.sparse` (`pip install scipy`) — for handling sparse matrices  \n",
    "  * `sklearn.feature_extraction.text.TfidfVectorizer` — for text vectorisation  \n",
    "  * `sklearn.metrics.confusion_matrix` — for evaluation  \n",
    "  * `sklearn.model_selection` (`GroupKFold`, `GridSearchCV`, `cross_val_predict`) — for grouped cross-validation and hyperparameter tuning  \n",
    "  * `sklearn.svm.LinearSVC` — for linear SVM classification  \n",
    "\n",
    "* **Defines file paths**  \n",
    "  * `DICT_D` — directory containing reduced dictionaries (`funct.txt`, `norm.txt`)  \n",
    "  * `GOLD_CSV` — 10k-sentence golden dataset from Phase 3.3  \n",
    "  * `MODEL_DIR` — output folder for trained models and artifacts  \n",
    "\n",
    "* **Loads dictionaries**  \n",
    "  * `load_vocab(fname)` — reads a dictionary into a lowercase term set  \n",
    "  * Loads `vocab_funct` and `vocab_norm`  \n",
    "\n",
    "* **Loads and prepares golden dataset**  \n",
    "  * Reads `GOLD_CSV` and ensures a `label` column exists  \n",
    "  * Keeps only rows with labels in `{funct, norm}`  \n",
    "  * Converts `label` to binary target `y` (`1 = normative`, `0 = functional`)  \n",
    "  * Stores `doc_id` for grouped cross-validation (ensuring no sentence leakage across folds)  \n",
    "\n",
    "* **Feature engineering**  \n",
    "  * `dict_flags(text)` — produces two binary features per sentence:  \n",
    "    – `funct_cnt`: at least one functional term present  \n",
    "    – `norm_cnt`: at least one normative term present  \n",
    "  * Generates a `dict_df` DataFrame of these features  \n",
    "  * Computes TF–IDF vectors with:  \n",
    "    – unigrams and bigrams (`ngram_range=(1, 2)`)  \n",
    "    – terms appearing in ≥20 documents and ≤90% of documents  \n",
    "  * Concatenates TF–IDF matrix with dictionary-flag features into a final sparse feature matrix `X`  \n",
    "\n",
    "* **Model selection via cross-validation**  \n",
    "  * Uses `GroupKFold(n_splits=10)` for grouped CV (by `doc_id`)  \n",
    "  * Runs `GridSearchCV` over `LinearSVC(class_weight=\"balanced\")` with `C ∈ {0.1, 0.5, 1, 3, 10}`  \n",
    "  * Selects the `C` value with the highest mean F1 score  \n",
    "  * Produces cross-validated predictions for confusion matrix analysis  \n",
    "\n",
    "* **Final model training and saving**  \n",
    "  * Trains the best `LinearSVC` on the full dataset  \n",
    "  * Saves artifacts to `MODEL_DIR`:  \n",
    "    – `svm_norm_funct.joblib` (trained SVM)  \n",
    "    – `tfidf_vectorizer.joblib` (TF–IDF vectoriser)  \n",
    "    – `gold_dict_features.csv` (dictionary match features for the golden set)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bc051c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, joblib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import (GroupKFold, GridSearchCV,\n",
    "                                     cross_val_predict)\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "BASE    = Path(__file__).resolve().parent          \n",
    "DICT_D  = BASE / \"dict_v2\"                         \n",
    "GOLD_CSV = BASE / \"2_golden_text.csv\"              \n",
    "\n",
    "\n",
    "def load_vocab(fname: str):\n",
    "    path = DICT_D / fname\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Dictionary file missing: {path}\")\n",
    "    return {ln.strip().lower() for ln in path.open(encoding=\"utf-8\")\n",
    "            if ln.strip()}\n",
    "\n",
    "vocab_funct = load_vocab(\"funct.txt\")\n",
    "vocab_norm  = load_vocab(\"norm.txt\")\n",
    "\n",
    "gold = pd.read_csv(GOLD_CSV)\n",
    "if \"label\" not in gold.columns:\n",
    "    raise ValueError(\"'label' column not found in golden file\")\n",
    "\n",
    "gold = gold[gold[\"label\"].isin([\"funct\", \"norm\"])].reset_index(drop=True)\n",
    "gold[\"y\"] = (gold[\"label\"] == \"norm\").astype(int)    # 1 = Normative\n",
    "\n",
    "token_pat = re.compile(r\"\\b\\w+\\b\")\n",
    "\n",
    "def dict_flags(text: str):\n",
    "    toks = token_pat.findall(text.lower())\n",
    "    return [\n",
    "        int(any(t in vocab_funct for t in toks)),     # funct_cnt\n",
    "        int(any(t in vocab_norm  for t in toks)),     # norm_cnt\n",
    "    ]\n",
    "\n",
    "flags = np.array([dict_flags(t) for t in gold[\"sentence\"]])\n",
    "dict_df = pd.DataFrame(flags, columns=[\"funct_cnt\", \"norm_cnt\"])\n",
    "\n",
    "# TF-IDF matrix\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 2),\n",
    "                        min_df=20,\n",
    "                        max_df=0.9)\n",
    "X_tfidf = tfidf.fit_transform(gold[\"sentence\"])\n",
    "\n",
    "# merge sparse + dense\n",
    "X = hstack([X_tfidf, csr_matrix(flags)])\n",
    "y = gold[\"y\"].values\n",
    "groups = gold[\"doc_id\"]              # group CV by document\n",
    "\n",
    "\n",
    "param_grid = {\"C\": [0.1, 0.5, 1, 3, 10]}\n",
    "svm = LinearSVC(class_weight=\"balanced\")\n",
    "\n",
    "cv = GroupKFold(n_splits=10)\n",
    "gs = GridSearchCV(svm, param_grid, cv=cv,\n",
    "                  scoring=\"f1\", n_jobs=-1, verbose=1)\n",
    "\n",
    "gs.fit(X, y, groups=groups)\n",
    "\n",
    "# Confusion matrix on CV predictions\n",
    "y_pred_cv = cross_val_predict(gs.best_estimator_, X, y, cv=cv, groups=groups)\n",
    "cm = pd.DataFrame(confusion_matrix(y, y_pred_cv),\n",
    "                  index=[\"True_Funct\", \"True_Norm\"],\n",
    "                  columns=[\"Pred_Funct\", \"Pred_Norm\"])\n",
    "\n",
    "best_svm = gs.best_estimator_.fit(X, y)\n",
    "\n",
    "MODEL_DIR = BASE / \"models\"\n",
    "MODEL_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "joblib.dump(best_svm, MODEL_DIR / \"svm_norm_funct.joblib\")\n",
    "joblib.dump(tfidf,    MODEL_DIR / \"tfidf_vectorizer.joblib\")\n",
    "dict_df.to_csv(MODEL_DIR / \"gold_dict_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544198e0",
   "metadata": {},
   "source": [
    "### **Phase 3.5 — Applying trained classifier to the full corpus**\n",
    "\n",
    "This phase loads the trained SVM classifier and TF–IDF vectoriser from Phase 3.4, reconstructs features for the entire cleaned corpus, applies the model to generate predictions, and outputs an auto-labelled dataset for downstream analysis.\n",
    "\n",
    "**Process**\n",
    "\n",
    "* **Imports required tools**  \n",
    "  * `pandas` — for corpus loading and output  \n",
    "  * `re` — for tokenisation and dictionary matching  \n",
    "  * `joblib` — for loading persisted models  \n",
    "  * `numpy` — for array handling  \n",
    "  * `Path` from `pathlib` — for path handling  \n",
    "  * `scipy.sparse` — for combining sparse feature matrices  \n",
    "\n",
    "* **Defines file paths**  \n",
    "  * `MODEL_D` — directory with saved `svm_norm_funct.joblib` and `tfidf_vectorizer.joblib`  \n",
    "  * `CORPUS_CSV` — full cleaned corpus at the sentence level (`1_documents.csv`)  \n",
    "  * `DICT_DIR` — reduced dictionary directory (`funct.txt`, `norm.txt`)  \n",
    "  * `OUT_CSV` — output file containing corpus plus predicted labels (`3_pred_documents.csv`)  \n",
    "\n",
    "* **Loads model and vectoriser**  \n",
    "  * Loads trained `LinearSVC` model from Phase 3.4  \n",
    "  * Loads `TfidfVectorizer` fitted on the golden set vocabulary  \n",
    "\n",
    "* **Loads dictionaries and defines feature function**  \n",
    "  * Reads `funct.txt` and `norm.txt` into term sets  \n",
    "  * `dict_counts(text)` tokenises a sentence and returns two binary features:  \n",
    "    – `funct_cnt = 1` if any functional term present  \n",
    "    – `norm_cnt = 1` if any normative term present  \n",
    "\n",
    "* **Loads full corpus**  \n",
    "  * Reads `1_documents.csv` containing all sentences to be classified  \n",
    "\n",
    "* **Builds feature matrix**  \n",
    "  * Applies `dict_counts` to each sentence to create a binary feature DataFrame  \n",
    "  * Transforms sentences into TF–IDF vectors using the loaded vectoriser  \n",
    "  * Horizontally stacks the TF–IDF matrix with dictionary-flag features into a unified sparse matrix (`X_full`)  \n",
    "\n",
    "* **Generates predictions**  \n",
    "  * Uses `svm_model.predict()` to classify each sentence as **Normative (1)** or **Functional (0)**  \n",
    "  * Stores predictions in new column `pred_normative`  \n",
    "  * Writes full dataset with predictions to `3_pred_documents.csv`  \n",
    "\n",
    "* **Performs sanity checks**  \n",
    "  * Computes proportion of sentences predicted as normative  \n",
    "  * Samples 10 random sentences from each predicted class for quick qualitative inspection  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e920771",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd, re, joblib, numpy as np\n",
    "from pathlib import Path\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "BASE     = Path(__file__).resolve().parent       \n",
    "MODEL_D  = BASE / \"models\"\n",
    "CORPUS_CSV = BASE / \"1_documents.csv\"\n",
    "OUT_CSV    = BASE / \"3_pred_documents.csv\"\n",
    "DICT_DIR   = BASE / \"dict_V2\"\n",
    "svm_path   = MODEL_D / \"svm_norm_funct.joblib\"\n",
    "vec_path   = MODEL_D / \"tfidf_vectorizer.joblib\"\n",
    "svm_model  = joblib.load(svm_path)\n",
    "tfidf_vec  = joblib.load(vec_path)\n",
    "\n",
    "\n",
    "def load_vocab(fname):\n",
    "    return {ln.strip().lower()\n",
    "            for ln in (DICT_DIR/fname).open(encoding=\"utf-8\") if ln.strip()}\n",
    "\n",
    "vocab_funct = load_vocab(\"funct.txt\")\n",
    "vocab_norm  = load_vocab(\"norm.txt\")\n",
    "\n",
    "token_pat = re.compile(r\"\\b\\w+\\b\")\n",
    "def dict_counts(text):\n",
    "    toks = token_pat.findall(text.lower())\n",
    "    return {\n",
    "        \"funct_cnt\": int(any(t in vocab_funct for t in toks)),\n",
    "        \"norm_cnt\":  int(any(t in vocab_norm  for t in toks))\n",
    "    }\n",
    "\n",
    "\n",
    "df = pd.read_csv(CORPUS_CSV)\n",
    "\n",
    "dict_df      = df[\"sentence\"].apply(dict_counts).apply(pd.Series)\n",
    "X_other      = csr_matrix(dict_df.values)\n",
    "X_tfidf      = tfidf_vec.transform(df[\"sentence\"].astype(str))\n",
    "X_full       = hstack([X_tfidf, X_other])\n",
    "\n",
    "df[\"pred_normative\"] = svm_model.predict(X_full)   # 1 = Normative, 0 = Functional\n",
    "df.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "share_norm = df[\"pred_normative\"].mean()\n",
    "\n",
    "# Sample 10 sentences of each class for eyeballing\n",
    "def sample_text(cls, n=10):\n",
    "    rows = df[df[\"pred_normative\"]==cls].sample(n=min(n, (df[\"pred_normative\"]==cls).sum()),\n",
    "                                                random_state=1)[\"sentence\"]\n",
    "    tag  = \"Normative\" if cls==1 else \"Functional\"\n",
    "    print(f\"\\n---- Random {len(rows)} {tag} sentences ----\")\n",
    "    for s in rows:\n",
    "        print(\"•\", s[:200].replace(\"\\n\",\" \") + (\"...\" if len(s)>200 else \"\"))\n",
    "\n",
    "sample_text(1)   # Normative examples\n",
    "sample_text(0)   # Functional examples\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2208204a",
   "metadata": {},
   "source": [
    "### **Phase 4.0 –– Handcoded scaling** \n",
    "\n",
    "Although we first attempted to hand-code extreme cases for supervised scaling with partial automation assistance, the quality of both the output and the auto-labelling proved problematic. We therefore decided to randomly select corpora with high frequencies of projection and protection to identify our scale items. The result was two seed baskets, stored as 4_projseed.txt and 4_protseed.txt.\n",
    "\n",
    "These seed sets served as the virgin texts and golden sets on which we trained the projection/protection classifier, which was subsequently applied to the corpus. Since the previous SVM stage had already isolated normative sentences, and our aim was to distinguish projection vs protection within normative content, we used the output of Phase 3.5 as our primary DataFrame for this stage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbf4505",
   "metadata": {},
   "source": [
    "### **Phase 4.1 — Applying projection/protection seeds**\n",
    "\n",
    "This step prepares the projection and protection seed sentences that anchor the supervised scaling process.  \n",
    "It normalises, labels, and combines the two seed sets into a single reference table used for projection–protection classification.\n",
    "\n",
    "**Process**\n",
    "\n",
    "* **Imports required tools**  \n",
    "  * `pandas` (`pip install pandas`) — for table creation and CSV writing  \n",
    "  * `unicodedata` — for Unicode normalisation  \n",
    "  * `Path` from `pathlib` — for file path handling  \n",
    "\n",
    "* **Defines file paths**  \n",
    "  * `BASE` — project root directory  \n",
    "  * `PROJ_TXT` — path to projection seed sentences (`4_projseed.txt`)  \n",
    "  * `PROT_TXT` — path to protection seed sentences (`4_protseed.txt`)  \n",
    "  * `OUT_CSV` — output file for combined seeds (`4_PPGS.csv`)  \n",
    "\n",
    "* **Defines helper functions**  \n",
    "  * `normalize_sentence(s)` — applies Unicode NFKC normalisation, trims stray quotes/spaces, and collapses multiple spaces into one  \n",
    "  * `read_sentences(path)` — reads lines from a text file, normalises them, and removes empty entries  \n",
    "\n",
    "* **Reads and labels seed sentences**  \n",
    "  * Loads projection seeds from `PROJ_TXT` and labels them `\"proj\"`  \n",
    "  * Loads protection seeds from `PROT_TXT` and labels them `\"prot\"`  \n",
    "\n",
    "* **Builds DataFrame and saves output**  \n",
    "  * Combines both labelled sets into a single DataFrame  \n",
    "  * Removes duplicates based on the `sentence` column  \n",
    "  * Saves the combined dataset to `4_PPGS.csv` in UTF-8 encoding  \n",
    "\n",
    "* **Output**  \n",
    "  * Prints confirmation of output path and row count  \n",
    "  * Displays the first five rows for verification  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468addd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(\"/Users/bornaardehi/Desktop/TAD\")\n",
    "PROJ_TXT = BASE / \"4_projseed.txt\"\n",
    "PROT_TXT = BASE / \"4_protseed.txt\"\n",
    "OUT_CSV  = BASE / \"4_PPGS.csv\"\n",
    "\n",
    "def normalize_sentence(s: str) -> str:\n",
    "    s = unicodedata.normalize(\"NFKC\", s)  # normalize quotes, spaces, etc.\n",
    "    s = s.strip()\n",
    "    s = s.strip(' \"\\'')  # strip stray quotes\n",
    "    # collapse multiple spaces\n",
    "    while \"  \" in s:\n",
    "        s = s.replace(\"  \", \" \")\n",
    "    return s\n",
    "\n",
    "def read_sentences(path: Path):\n",
    "    \"\"\"Read non-empty, cleaned lines from a .txt file.\"\"\"\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = [normalize_sentence(line) for line in f]\n",
    "    # remove empties\n",
    "    return [ln for ln in lines if ln]\n",
    "\n",
    "proj_sentences = read_sentences(PROJ_TXT)\n",
    "prot_sentences = read_sentences(PROT_TXT)\n",
    "\n",
    "rows = []\n",
    "rows.extend({\"sentence\": s, \"label\": \"proj\"} for s in proj_sentences)\n",
    "rows.extend({\"sentence\": s, \"label\": \"prot\"} for s in prot_sentences)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df = df.drop_duplicates(subset=[\"sentence\"]).reset_index(drop=True)\n",
    "df.to_csv(OUT_CSV, index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c13232",
   "metadata": {},
   "source": [
    "### **Phase 4.2 — Projection vs protection supervised scaling**\n",
    "\n",
    "This phase trains a supervised model to distinguish **projection** from **protection** within normative sentences, using the manually validated gold seed set from Phase 4.1.  \n",
    "The trained model is then applied to the normative-only subset of the full corpus (from Phase 3.5), generating both **sentence-level** and **aggregated organisation–year** projection/protection scores for further analysis.\n",
    "\n",
    "**Process**\n",
    "\n",
    "* **Imports required tools**  \n",
    "  * `pandas` (`pip install pandas`) — for dataset manipulation  \n",
    "  * `Path` from `pathlib` — for file path management  \n",
    "  * `TfidfVectorizer` from `sklearn.feature_extraction.text` — for converting text into TF–IDF features  \n",
    "  * `LogisticRegression` from `sklearn.linear_model` — for binary classification  \n",
    "  * `Pipeline` from `sklearn.pipeline` — for chaining preprocessing and modelling  \n",
    "  * `cross_val_score` from `sklearn.model_selection` — for cross-validation accuracy estimation  \n",
    "  * `joblib` — for saving the trained model  \n",
    "\n",
    "* **Defines file paths**  \n",
    "  * `CORPUS` — full corpus with SVM-predicted normative/functional labels (`3_pred_documents.csv`)  \n",
    "  * `GOLDSEEDS` — labelled gold seeds from Phase 4.1 (`4_PPGS.csv`)  \n",
    "  * `MODEL_DIR` — directory for saving the trained projection/protection model  \n",
    "  * `OUT_SENT` — sentence-level output file (`4_norm_sentences_pp_SUP.csv`)  \n",
    "  * `OUT_YEAR` — aggregated organisation–year output file (`4_org_year_pp_SUP.csv`)  \n",
    "\n",
    "* **Loads and encodes gold seeds**  \n",
    "  * Reads `4_PPGS.csv` and reports label counts  \n",
    "  * Encodes labels: `\"proj\" → 1`, `\"prot\" → 0`  \n",
    "\n",
    "* **Trains TF–IDF + Logistic Regression classifier**  \n",
    "  * Configures `TfidfVectorizer`: unigrams and bigrams, `min_df=2`, `max_df=0.9`, lowercasing  \n",
    "  * Configures `LogisticRegression`: balanced class weights, `liblinear` solver  \n",
    "  * Wraps both into a `Pipeline`  \n",
    "  * Runs **5-fold cross-validation** on the gold seeds, printing mean accuracy ± std  \n",
    "  * Fits the model on the full seed set  \n",
    "  * Saves the trained pipeline to `pp_scaler.joblib`  \n",
    "\n",
    "* **Filters normative sentences in the corpus**  \n",
    "  * Loads full corpus from Phase 3.5 (`3_pred_documents.csv`)  \n",
    "  * Keeps only rows where `pred_normative == 1`  \n",
    "\n",
    "* **Scores projection/protection probabilities**  \n",
    "  * Applies the trained model to normative sentences using `.predict_proba()`  \n",
    "  * Extracts probability of projection (`pp_score`)  \n",
    "  * Creates binary prediction: `proj_pred = 1` if `pp_score ≥ 0.5` else `0`  \n",
    "\n",
    "* **Saves sentence-level results**  \n",
    "  * Writes normative-only DataFrame with scores and predictions to `4_norm_sentences_pp_SUP.csv`  \n",
    "\n",
    "* **Aggregates by organisation–year**  \n",
    "  * Groups normative sentences by `(org, year)`  \n",
    "  * Computes:  \n",
    "    – `pp_mean`: mean projection probability  \n",
    "    – `share_proj`: share of projection predictions  \n",
    "    – `n_sent`: number of normative sentences  \n",
    "  * Derives `share_prot = 1 − share_proj`  \n",
    "  * Saves tidy aggregated DataFrame to `4_org_year_pp_SUP.csv`  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fce72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import joblib\n",
    "\n",
    "BASE        = Path(\"/Users/bornaardehi/Desktop/TAD\")\n",
    "CORPUS      = BASE / \"3_pred_documents.csv\"   # from SVM step\n",
    "GOLDSEEDS   = BASE / \"4_PPGS.csv\"             # validated PP gold seeds\n",
    "MODEL_DIR   = BASE / \"models\"\n",
    "MODEL_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "OUT_SENT    = BASE / \"4_norm_sentences_pp_SUP.csv\"\n",
    "OUT_YEAR    = BASE / \"4_org_year_pp_SUP.csv\"\n",
    "\n",
    "seeds = pd.read_csv(GOLDSEEDS)\n",
    "\n",
    "# Encode label: proj -> 1, prot -> 0\n",
    "seeds[\"y\"] = seeds[\"label\"].map({\"proj\": 1, \"prot\": 0})\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,\n",
    "    max_df=0.9,\n",
    "    lowercase=True\n",
    ")\n",
    "\n",
    "clf = LogisticRegression(\n",
    "    solver=\"liblinear\",\n",
    "    C=1.0,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"tfidf\", vectorizer),\n",
    "    (\"logit\", clf)\n",
    "])\n",
    "\n",
    "# Cross-validation for sanity\n",
    "scores = cross_val_score(pipe, seeds[\"sentence\"], seeds[\"y\"], cv=5, scoring=\"accuracy\")\n",
    "\n",
    "# Fit final model\n",
    "pipe.fit(seeds[\"sentence\"], seeds[\"y\"])\n",
    "joblib.dump(pipe, MODEL_DIR / \"pp_scaler.joblib\")\n",
    "\n",
    "df = pd.read_csv(CORPUS)\n",
    "if \"pred_normative\" not in df.columns:\n",
    "    raise ValueError(\"Corpus must have 'pred_normative' column from SVM step.\")\n",
    "\n",
    "norm_df = df[df[\"pred_normative\"] == 1].copy()\n",
    "\n",
    "pp_probs = pipe.predict_proba(norm_df[\"sentence\"])[:, 1]  # probability of proj=1\n",
    "norm_df[\"pp_score\"] = pp_probs\n",
    "norm_df[\"proj_pred\"] = (norm_df[\"pp_score\"] >= 0.5).astype(int)\n",
    "\n",
    "norm_df.to_csv(OUT_SENT, index=False)\n",
    "\n",
    "if {\"org\", \"year\"}.issubset(norm_df.columns):\n",
    "    # make sure year is numeric (optional but handy)\n",
    "    try:\n",
    "        norm_df[\"year\"] = norm_df[\"year\"].astype(int)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    agg = (norm_df.groupby([\"org\", \"year\"], as_index=False)\n",
    "           .agg(pp_mean=(\"pp_score\", \"mean\"),\n",
    "                share_proj=(\"proj_pred\", \"mean\"),\n",
    "                n_sent=(\"sentence\", \"count\")))\n",
    "\n",
    "    # derive protection share from projection share\n",
    "    agg[\"share_prot\"] = 1.0 - agg[\"share_proj\"]\n",
    "\n",
    "    # tidy column order\n",
    "    agg = agg[[\"org\", \"year\", \"pp_mean\", \"share_proj\", \"share_prot\", \"n_sent\"]]\n",
    "\n",
    "    agg.to_csv(OUT_YEAR, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdad91b",
   "metadata": {},
   "source": [
    "### **Phase 4.3 — Diagnostics and optional retraining for projection/protection scaling**\n",
    "\n",
    "This phase provides a diagnostic and retraining framework for the projection/protection (PP) classifier.  \n",
    "It loads the gold seed set and normative-only sentences, evaluates cross-validation performance, displays top discriminative features, optionally retrains the model with custom vectorisation parameters, and applies the updated model to score projection/protection probabilities at both **sentence** and **organisation–year** levels.\n",
    "\n",
    "**Process**\n",
    "\n",
    "* **Imports required tools**  \n",
    "  * `argparse` — for CLI argument parsing  \n",
    "  * `os`, `sys` — for path handling and error exits  \n",
    "  * `pandas`, `numpy` — for data handling  \n",
    "  * `TfidfVectorizer` — for text feature extraction  \n",
    "  * `LogisticRegression` — for binary classification  \n",
    "  * `Pipeline` — for chaining TF–IDF and classifier  \n",
    "  * `StratifiedKFold`, `cross_val_score`, `cross_val_predict` — for model evaluation  \n",
    "  * `classification_report`, `accuracy_score`, `f1_score` — for performance metrics  \n",
    "  * `Bunch` from `sklearn.utils` — for structured data returns  \n",
    "  * `dump` from `joblib` — for saving trained models  \n",
    "\n",
    "* **Helper functions**  \n",
    "  * `find_text_col()` — identifies the text column in a DataFrame (prefers `sentence`, `text`, or `content`)  \n",
    "  * `load_seeds(path)` — loads gold seed CSV, maps projection/protection labels to binary (`proj=1`, `prot=0`), returns features and labels  \n",
    "  * `load_normative_sentences(path)` — loads corpus, filters to normative sentences based on `pred_normative` flag, returns text and metadata  \n",
    "  * `make_pipeline()` — creates a TF–IDF + Logistic Regression pipeline with configurable n-gram range, min/max DF, and `C` parameter  \n",
    "  * `show_top_features()` — prints the top k projection and protection n-grams with coefficients  \n",
    "  * `evaluate_cv()` — runs stratified k-fold CV, prints accuracy/F1, and classification report  \n",
    "  * `score_normative()` — applies model to normative sentences, outputs top projection and protection examples, and returns scored DataFrame  \n",
    "  * `aggregate_org_year()` — aggregates projection/protection scores by organisation and year if metadata available  \n",
    "\n",
    "* **Main workflow**  \n",
    "  * Loads gold seed set (`--seeds_csv`), reports counts by class  \n",
    "  * Builds TF–IDF + Logistic Regression pipeline with parameters from CLI arguments  \n",
    "  * Evaluates model via cross-validation on seed set, printing accuracy, F1, and classification report  \n",
    "  * Fits the model on the full seed set and prints top features  \n",
    "  * Saves trained model to `--model_dir/pp_scaler.joblib`  \n",
    "\n",
    "* **Scoring and output**  \n",
    "  * Loads normative sentences from `--normative_csv`  \n",
    "  * Scores each sentence with projection probability (`pp_score`) and binary projection label (`proj_pred`)  \n",
    "  * Saves sentence-level results to `--sent_out`  \n",
    "  * Aggregates by `(org, year)` to compute:  \n",
    "    – `pp_mean`: mean projection probability  \n",
    "    – `share_proj`: share of projection predictions  \n",
    "    – `share_prot`: complement of `share_proj`  \n",
    "    – `n_sent`: number of normative sentences in group  \n",
    "  * Saves results to `--agg_out` if metadata available  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4c9b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.utils import Bunch\n",
    "from joblib import dump\n",
    "\n",
    "# Helpers\n",
    "def find_text_col(df, preferred=(\"sentence\",\"text\",\"content\")):\n",
    "    for c in preferred:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    # fallback: choose first object dtype column\n",
    "    for c in df.columns:\n",
    "        if df[c].dtype == \"object\":\n",
    "            return c\n",
    "    raise ValueError(\"Couldn't find a text column. Expected one of: \" + \", \".join(preferred))\n",
    "\n",
    "def load_seeds(path):\n",
    "    df = pd.read_csv(path)\n",
    "    text_col = find_text_col(df)\n",
    "    # normalise label column\n",
    "    if \"label\" in df.columns:\n",
    "        y = df[\"label\"]\n",
    "    elif \"class\" in df.columns:\n",
    "        y = df[\"class\"]\n",
    "    elif \"pp_label\" in df.columns:\n",
    "        y = df[\"pp_label\"]\n",
    "    else:\n",
    "        raise ValueError(\"Seed CSV needs a label column (label/class/pp_label).\")\n",
    "    y = y.str.strip().str.lower().map({\"proj\":1, \"protection\":0, \"prot\":0, \"projection\":1})\n",
    "    if y.isna().any():\n",
    "        bad = df.loc[y.isna()]\n",
    "        raise ValueError(f\"Unrecognised labels in seeds:\\n{bad[['label'] if 'label' in df.columns else y.name].head()}\")\n",
    "    X = df[text_col].astype(str)\n",
    "    return Bunch(X=X, y=y.values, text_col=text_col, raw=df)\n",
    "\n",
    "def load_normative_sentences(path):\n",
    "    df = pd.read_csv(path)\n",
    "    # expect pred_normative column\n",
    "    pred_col = None\n",
    "    for c in (\"pred_normative\", \"is_normative\", \"normative_pred\", \"normative\"):\n",
    "        if c in df.columns:\n",
    "            pred_col = c\n",
    "            break\n",
    "    if pred_col is None:\n",
    "        raise ValueError(\"3_pred_documents.csv must contain a normative flag column (pred_normative).\")\n",
    "    text_col = find_text_col(df)\n",
    "    meta_cols = [c for c in (\"org\",\"year\") if c in df.columns]\n",
    "    df = df.loc[df[pred_col] == 1].copy()\n",
    "    df[text_col] = df[text_col].astype(str)\n",
    "    return Bunch(df=df, text_col=text_col, meta_cols=meta_cols)\n",
    "\n",
    "def make_pipeline(ngram_lo, ngram_hi, min_df, max_df, C, use_class_weight=True):\n",
    "    vec = TfidfVectorizer(\n",
    "        ngram_range=(ngram_lo, ngram_hi),\n",
    "        min_df=min_df,\n",
    "        max_df=max_df,\n",
    "        strip_accents=\"unicode\",\n",
    "        lowercase=True\n",
    "    )\n",
    "    lr = LogisticRegression(\n",
    "        solver=\"liblinear\",\n",
    "        C=C,\n",
    "        class_weight=\"balanced\" if use_class_weight else None,\n",
    "        max_iter=2000\n",
    "    )\n",
    "    return Pipeline([(\"tfidf\", vec), (\"lr\", lr)])\n",
    "\n",
    "def show_top_features(model, k=30):\n",
    "    vec = model.named_steps[\"tfidf\"]\n",
    "    lr = model.named_steps[\"lr\"]\n",
    "    feats = np.array(vec.get_feature_names_out())\n",
    "    coefs = lr.coef_.ravel()\n",
    "    top_proj_idx = np.argsort(coefs)[-k:][::-1]\n",
    "    top_prot_idx = np.argsort(coefs)[:k]\n",
    "    print(\"\\n=== Top projection n-grams ===\")\n",
    "    for i in top_proj_idx:\n",
    "        print(f\"{feats[i]:40s}  coef= {coefs[i]: .3f}\")\n",
    "    print(\"\\n=== Top protection n-grams ===\")\n",
    "    for i in top_prot_idx:\n",
    "        print(f\"{feats[i]:40s}  coef= {coefs[i]: .3f}\")\n",
    "\n",
    "def evaluate_cv(pipe, X, y, n_splits=5, seed=42):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    acc = cross_val_score(pipe, X, y, cv=skf, scoring=\"accuracy\")\n",
    "    f1  = cross_val_score(pipe, X, y, cv=skf, scoring=\"f1\")\n",
    "    print(f\"CV accuracy: {acc.mean():.3f} ± {acc.std():.3f}\")\n",
    "    print(f\"CV F1 (proj=1): {f1.mean():.3f} ± {f1.std():.3f}\")\n",
    "\n",
    "    # detailed report via cross_val_predict\n",
    "    yhat = cross_val_predict(pipe, X, y, cv=skf, method=\"predict\")\n",
    "    print(\"\\nClassification report (proj=1, prot=0):\")\n",
    "    print(classification_report(y, yhat, digits=3))\n",
    "\n",
    "def score_normative(pipe, norm: Bunch, top_k=20):\n",
    "    X = norm.df[norm.text_col].values\n",
    "    proba = pipe.predict_proba(X)[:,1]\n",
    "    out = norm.df.copy()\n",
    "    out[\"pp_score\"] = proba\n",
    "    out[\"proj_pred\"] = (out[\"pp_score\"] > 0.5).astype(int)\n",
    "    # Top/bottom samples\n",
    "    top = out.sort_values(\"pp_score\", ascending=False).head(top_k)\n",
    "    bot = out.sort_values(\"pp_score\", ascending=True).head(top_k)\n",
    "    print(\"\\n=== Top projection sentences ===\")\n",
    "    for i, row in top.iterrows():\n",
    "        preview = row[norm.text_col].replace(\"\\n\",\" \")[:280]\n",
    "        print(f\"[{row.get('org','?')}/{row.get('year','?')}]  {row['pp_score']:.3f}  {preview}\")\n",
    "    print(\"\\n=== Top protection sentences ===\")\n",
    "    for i, row in bot.iterrows():\n",
    "        preview = row[norm.text_col].replace(\"\\n\",\" \")[:280]\n",
    "        print(f\"[{row.get('org','?')}/{row.get('year','?')}]  {row['pp_score']:.3f}  {preview}\")\n",
    "    return out\n",
    "\n",
    "def aggregate_org_year(df, meta_cols):\n",
    "    need = {\"org\",\"year\"}\n",
    "    have = set(meta_cols)\n",
    "    if not need.issubset(have):\n",
    "        print(\"(!) org/year not found — skipping org-year aggregation.\")\n",
    "        return None\n",
    "    gp = df.groupby([\"org\",\"year\"])\n",
    "    agg = gp.agg(\n",
    "        pp_mean=(\"pp_score\",\"mean\"),\n",
    "        share_proj=(\"proj_pred\",\"mean\"),\n",
    "        n_sent=(\"proj_pred\",\"size\")\n",
    "    ).reset_index()\n",
    "    agg[\"share_prot\"] = 1.0 - agg[\"share_proj\"]\n",
    "    # order\n",
    "    agg = agg[[\"org\",\"year\",\"pp_mean\",\"share_proj\",\"share_prot\",\"n_sent\"]]\n",
    "    return agg\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    seeds = load_seeds(args.seeds_csv)\n",
    "    print(f\"Loaded seeds: {len(seeds.X)} (proj={seeds.y.sum()}, prot={len(seeds.y)-seeds.y.sum()})\")\n",
    "\n",
    "    pipe = make_pipeline(\n",
    "        ngram_lo=args.ngram_lo,\n",
    "        ngram_hi=args.ngram_hi,\n",
    "        min_df=args.min_df,\n",
    "        max_df=args.max_df,\n",
    "        C=args.C,\n",
    "        use_class_weight=not args.no_class_weight\n",
    "    )\n",
    "\n",
    "    print(\"\\n[Step 5] Cross-validation on seeds\")\n",
    "    evaluate_cv(pipe, seeds.X, seeds.y, n_splits=args.cv_folds)\n",
    "\n",
    "    print(\"\\nFit on full seed set…\")\n",
    "    pipe.fit(seeds.X, seeds.y)\n",
    "    show_top_features(pipe, k=args.top_k)\n",
    "\n",
    "    # Save model\n",
    "    os.makedirs(args.model_dir, exist_ok=True)\n",
    "    model_path = os.path.join(args.model_dir, \"pp_scaler.joblib\")\n",
    "    dump(pipe, model_path)\n",
    "    print(f\"\\n✓ Saved model to {model_path}\")\n",
    "\n",
    "    # Load normative sentences and score\n",
    "    print(\"\\nLoad normative sentences and re-score…\")\n",
    "    norm = load_normative_sentences(args.normative_csv)\n",
    "    scored = score_normative(pipe, norm, top_k=args.top_examples)\n",
    "\n",
    "    # Persist sentence-level scores\n",
    "    sent_out = args.sent_out\n",
    "    scored.to_csv(sent_out, index=False)\n",
    "    print(f\"✓ Saved sentence-level scores to {sent_out}\")\n",
    "\n",
    "    # Org-year aggregate (if meta available)\n",
    "    agg = aggregate_org_year(scored, norm.meta_cols)\n",
    "    if agg is not None:\n",
    "        agg_out = args.agg_out\n",
    "        agg.to_csv(agg_out, index=False)\n",
    "        print(f\"✓ Saved org-year aggregates to {agg_out}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    p = argparse.ArgumentParser(description=\"Diagnostics and retrain for projection/protection scaling\")\n",
    "    p.add_argument(\"--seeds_csv\", default=\"4_PPGS.csv\", help=\"Gold seed file\")\n",
    "    p.add_argument(\"--normative_csv\", default=\"3_pred_documents.csv\", help=\"Corpus with pred_normative flag\")\n",
    "\n",
    "    # Vectoriser / model knobs\n",
    "    p.add_argument(\"--ngram_lo\", type=int, default=1)\n",
    "    p.add_argument(\"--ngram_hi\", type=int, default=3)\n",
    "    p.add_argument(\"--min_df\", type=int, default=3)\n",
    "    p.add_argument(\"--max_df\", type=float, default=0.85)\n",
    "    p.add_argument(\"--C\", type=float, default=1.0)\n",
    "    p.add_argument(\"--no_class_weight\", action=\"store_true\", help=\"Disable class_weight=balanced\")\n",
    "\n",
    "    # CV / reporting\n",
    "    p.add_argument(\"--cv_folds\", type=int, default=5)\n",
    "    p.add_argument(\"--top_k\", type=int, default=30, help=\"How many top features to print per side\")\n",
    "    p.add_argument(\"--top_examples\", type=int, default=20, help=\"How many top/bottom sentences to print\")\n",
    "\n",
    "    # Paths out\n",
    "    p.add_argument(\"--model_dir\", default=\"models\")\n",
    "    p.add_argument(\"--sent_out\", default=\"4_norm_sentences_pp_SUP.csv\")\n",
    "    p.add_argument(\"--agg_out\", default=\"4_org_year_pp_SUP.csv\")\n",
    "\n",
    "    args = p.parse_args()\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de8cee2",
   "metadata": {},
   "source": [
    "### **Phase 5.0 — Descriptive statistical analysis of projection/protection results**\n",
    "\n",
    "This phase produces descriptive statistics, tests of group differences, temporal correlation analyses, and volatility measures based on the organisation–year projection/protection dataset from Phase 4.2 or 4.3 (`4_org_year_pp_SUP.csv`).  \n",
    "The outputs are saved as HTML tables for direct inspection and reporting.\n",
    "\n",
    "**Process**\n",
    "\n",
    "* **Imports required tools**  \n",
    "  * `pandas` (`pip install pandas`) — for data manipulation and HTML export  \n",
    "  * `numpy` (`pip install numpy`) — for numerical operations  \n",
    "  * `f_oneway` from `scipy.stats` — for one-way ANOVA  \n",
    "  * `pearsonr` from `scipy.stats` — for Pearson correlation  \n",
    "  * `pairwise_tukeyhsd` from `statsmodels.stats.multicomp` — for Tukey post-hoc tests  \n",
    "\n",
    "* **Loads and prepares dataset**  \n",
    "  * Reads `4_org_year_pp_SUP.csv` containing organisation–year projection/protection shares  \n",
    "  * Converts `year` column to integer type  \n",
    "\n",
    "* **Descriptive statistics**  \n",
    "  * **Overall stats** — computes count, mean, std, min, 25%, 50%, 75%, max for `share_proj`, `share_prot`, and `pp_mean`  \n",
    "  * Adds interquartile range (IQR)  \n",
    "  * Saves results to `desc_stats_overall.html`  \n",
    "  * **By-organisation stats** — computes mean, std, min, max per organisation for the same variables  \n",
    "  * Saves results to `desc_stats_by_org.html`  \n",
    "\n",
    "* **ANOVA and Tukey post-hoc tests**  \n",
    "  * Performs one-way ANOVA on `share_proj` grouped by organisation  \n",
    "  * Saves F-statistic and p-value to `anova_results.html`  \n",
    "  * Runs Tukey HSD to identify significant differences between organisations  \n",
    "  * Saves results to `tukey_results.html`  \n",
    "\n",
    "* **Time-trend correlations**  \n",
    "  * For each organisation with >1 unique year, computes Pearson correlation (`r`) between `year` and `share_proj` (with p-value)  \n",
    "  * Saves results to `trend_correlation_by_org.html`  \n",
    "\n",
    "* **Volatility analysis**  \n",
    "  * Sorts dataset by `org` and `year`  \n",
    "  * Computes year-to-year change (`delta_proj`) in `share_proj` within each organisation  \n",
    "  * Aggregates volatility stats per organisation (mean, std, max, min)  \n",
    "  * Saves results to `volatility_by_org.html`  \n",
    "  * Identifies top 20 largest absolute changes across all organisation–year pairs  \n",
    "  * Saves results to `top_volatility_cases.html`  \n",
    "\n",
    "* **Output**  \n",
    "  * All descriptive and inferential results are exported as separate HTML tables for direct viewing  \n",
    "  * Prints a completion message confirming successful saves  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2067023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import f_oneway, pearsonr\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "df = pd.read_csv(\"4_org_year_pp_SUP.csv\")\n",
    "df[\"year\"] = df[\"year\"].astype(int)\n",
    "\n",
    "# Descriptive Stats\n",
    "overall_stats = df[[\"share_proj\", \"share_prot\", \"pp_mean\"]].describe().T\n",
    "overall_stats[\"iqr\"] = df[[\"share_proj\", \"share_prot\", \"pp_mean\"]].quantile(0.75) - \\\n",
    "                       df[[\"share_proj\", \"share_prot\", \"pp_mean\"]].quantile(0.25)\n",
    "overall_stats.to_html(\"desc_stats_overall.html\")\n",
    "\n",
    "by_org_stats = df.groupby(\"org\")[[\"share_proj\", \"share_prot\", \"pp_mean\"]].agg(\n",
    "    [\"mean\", \"std\", \"min\", \"max\"]\n",
    ")\n",
    "by_org_stats.to_html(\"desc_stats_by_org.html\")\n",
    "\n",
    "# ANOVA + Tukey\n",
    "groups = [g[\"share_proj\"].values for _, g in df.groupby(\"org\")]\n",
    "anova_stat, anova_p = f_oneway(*groups)\n",
    "pd.DataFrame({\"F-stat\": [anova_stat], \"p-value\": [anova_p]}).to_html(\"anova_results.html\")\n",
    "\n",
    "tukey = pairwise_tukeyhsd(endog=df[\"share_proj\"], groups=df[\"org\"], alpha=0.05)\n",
    "tukey_df = pd.DataFrame(data=tukey._results_table.data[1:], columns=tukey._results_table.data[0])\n",
    "tukey_df.to_html(\"tukey_results.html\")\n",
    "\n",
    "# Time-trend correlation\n",
    "trend_corrs = []\n",
    "for org, g in df.groupby(\"org\"):\n",
    "    if g[\"year\"].nunique() > 1:\n",
    "        r, p = pearsonr(g[\"year\"], g[\"share_proj\"])\n",
    "        trend_corrs.append({\"org\": org, \"pearson_r\": r, \"p_value\": p})\n",
    "\n",
    "trend_df = pd.DataFrame(trend_corrs)\n",
    "trend_df.to_html(\"trend_correlation_by_org.html\")\n",
    "\n",
    "# Volatility\n",
    "df_sorted = df.sort_values([\"org\", \"year\"])\n",
    "df_sorted[\"delta_proj\"] = df_sorted.groupby(\"org\")[\"share_proj\"].diff()\n",
    "\n",
    "volatility_stats = df_sorted.groupby(\"org\")[\"delta_proj\"].agg([\"mean\", \"std\", \"max\", \"min\"])\n",
    "volatility_stats.to_html(\"volatility_by_org.html\")\n",
    "\n",
    "top_changes = df_sorted.sort_values(\"delta_proj\", key=abs, ascending=False).head(20)\n",
    "top_changes[[\"org\", \"year\", \"delta_proj\"]].to_html(\"top_volatility_cases.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10adde05",
   "metadata": {},
   "source": [
    "### **Phase 5.1 –– Graphs and visualizations of projection vs protection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c49e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "BASE = Path(\"/Users/bornaardehi/Desktop/TAD\")\n",
    "IN = BASE / \"4_org_year_pp_SUP.csv\"\n",
    "OUTS = {\n",
    "    \"proj_over_time_png\": BASE / \"viz_proj_share_over_time.png\",\n",
    "    \"proj_over_time_svg\": BASE / \"viz_proj_share_over_time.svg\",\n",
    "    \"prot_over_time_png\": BASE / \"viz_prot_share_over_time.png\",\n",
    "    \"prot_over_time_svg\": BASE / \"viz_prot_share_over_time.svg\",\n",
    "    \"avg_by_org_png\":     BASE / \"viz_proj_vs_prot_by_org.png\",\n",
    "    \"avg_by_org_svg\":     BASE / \"viz_proj_vs_prot_by_org.svg\",\n",
    "    \"extremes_csv\":       BASE / \"extreme_years_proj.csv\",\n",
    "    \"extremes_prot_csv\":  BASE / \"extreme_years_prot.csv\",\n",
    "    \"facet_proj_png\":     BASE / \"viz_proj_share_facets.png\",\n",
    "    \"facet_proj_svg\":     BASE / \"viz_proj_share_facets.svg\",\n",
    "}\n",
    "\n",
    "BASE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Style\n",
    "sns.set_theme(context=\"talk\", style=\"whitegrid\")\n",
    "palette = sns.color_palette(\"colorblind\")\n",
    "\n",
    "df = pd.read_csv(IN)\n",
    "keep = [\"org\", \"year\", \"share_proj\", \"share_prot\", \"pp_mean\"]\n",
    "df = df[[c for c in keep if c in df.columns]].copy()\n",
    "\n",
    "# types & dedupe\n",
    "df[\"year\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "df = df.dropna(subset=[\"org\", \"year\", \"share_proj\", \"share_prot\"]).drop_duplicates()\n",
    "# sort for nicer lines\n",
    "df = df.sort_values([\"org\", \"year\"])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=df, x=\"year\", y=\"share_proj\", hue=\"org\", marker=\"o\", palette=palette, linewidth=2)\n",
    "plt.title(\"Projection Share Over Time by Organisation\", fontsize=14)\n",
    "plt.ylabel(\"Share (Projection)\")\n",
    "plt.xlabel(\"Year\")\n",
    "# Trim legend if many orgs\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "if len(labels) > 20:\n",
    "    plt.legend([], [], frameon=False)\n",
    "else:\n",
    "    plt.legend(title=\"Organisation\", bbox_to_anchor=(1.02, 1), loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTS[\"proj_over_time_png\"], dpi=300)\n",
    "plt.savefig(OUTS[\"proj_over_time_svg\"])\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=df, x=\"year\", y=\"share_prot\", hue=\"org\", marker=\"o\", palette=palette, linewidth=2)\n",
    "plt.title(\"Protection Share Over Time by Organisation\", fontsize=14)\n",
    "plt.ylabel(\"Share (Protection)\")\n",
    "plt.xlabel(\"Year\")\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "if len(labels) > 20:\n",
    "    plt.legend([], [], frameon=False)\n",
    "else:\n",
    "    plt.legend(title=\"Organisation\", bbox_to_anchor=(1.02, 1), loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTS[\"prot_over_time_png\"], dpi=300)\n",
    "plt.savefig(OUTS[\"prot_over_time_svg\"])\n",
    "plt.close()\n",
    "\n",
    "if df[\"org\"].nunique() > 8:\n",
    "    g = sns.FacetGrid(df, col=\"org\", col_wrap=4, height=2.8, sharey=True)\n",
    "    g.map_dataframe(sns.lineplot, x=\"year\", y=\"share_proj\", marker=\"o\", linewidth=1.8)\n",
    "    g.set_titles(col_template=\"{col_name}\")\n",
    "    g.set_axis_labels(\"Year\", \"Share (Projection)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTS[\"facet_proj_png\"], dpi=300)\n",
    "    plt.savefig(OUTS[\"facet_proj_svg\"])\n",
    "    plt.close()\n",
    "\n",
    "avg_df = (\n",
    "    df.groupby(\"org\", as_index=False)\n",
    "      .agg(share_proj=(\"share_proj\", \"mean\"), share_prot=(\"share_prot\", \"mean\"))\n",
    "      .sort_values(\"share_proj\", ascending=False)\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = avg_df.plot(\n",
    "    x=\"org\",\n",
    "    y=[\"share_proj\", \"share_prot\"],\n",
    "    kind=\"bar\",\n",
    "    figsize=(12, 6),\n",
    "    legend=True\n",
    ")\n",
    "plt.title(\"Average Projection vs Protection by Organisation\", fontsize=14)\n",
    "plt.ylabel(\"Average Share\")\n",
    "plt.xlabel(\"\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTS[\"avg_by_org_png\"], dpi=300)\n",
    "plt.savefig(OUTS[\"avg_by_org_svg\"])\n",
    "plt.close()\n",
    "\n",
    "def extremes_by(group, col, n=2):\n",
    "    # Copy to avoid chained assignment, and handle cases with < n rows gracefully\n",
    "    top = group.nlargest(min(n, len(group)), columns=col)[[\"year\", col]].copy()\n",
    "    bot = group.nsmallest(min(n, len(group)), columns=col)[[\"year\", col]].copy()\n",
    "    top[\"which\"] = \"top\"\n",
    "    bot[\"which\"] = \"bottom\"\n",
    "    return pd.concat([top, bot], ignore_index=True)\n",
    "\n",
    "ext_list = []\n",
    "for org, g in df.groupby(\"org\"):\n",
    "    ex = extremes_by(g, \"share_proj\", n=2)\n",
    "    ex.insert(0, \"org\", org)\n",
    "    ext_list.append(ex)\n",
    "ext_proj = pd.concat(ext_list, ignore_index=True).sort_values([\"org\", \"which\", \"year\"])\n",
    "ext_proj.rename(columns={\"share_proj\": \"value\"}, inplace=True)\n",
    "ext_proj.to_csv(OUTS[\"extremes_csv\"], index=False)\n",
    "\n",
    "ext_list = []\n",
    "for org, g in df.groupby(\"org\"):\n",
    "    ex = extremes_by(g, \"share_prot\", n=2)\n",
    "    ex.insert(0, \"org\", org)\n",
    "    ext_list.append(ex)\n",
    "ext_prot = pd.concat(ext_list, ignore_index=True).sort_values([\"org\", \"which\", \"year\"])\n",
    "ext_prot.rename(columns={\"share_prot\": \"value\"}, inplace=True)\n",
    "ext_prot.to_csv(OUTS[\"extremes_prot_csv\"], index=False)\n",
    "\n",
    "for k, p in OUTS.items():"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885fd362",
   "metadata": {},
   "source": [
    "### **Phase 5.1 –– Graphs and visualizations of normative vs substansive**\n",
    "\n",
    "Since this step uses a different dataset but is following 'stage 1' of our research, it is not an issue to execute it after the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43113d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import math\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats import multitest\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter, MaxNLocator\n",
    "from datetime import datetime\n",
    "import html\n",
    "\n",
    "DATA_PATH = \"3_pred_documents.csv\"     \n",
    "OUTPUT_DIR = \"norm_func_outputs\"       \n",
    "MIN_COUNT_FOR_ORG_IN_CHISQ = 30        # rare orgs for chi-square\n",
    "TOP_N_FOR_FISHER = 12                  # pairwise Fisher across top-N orgs by volume\n",
    "TOP_N_FOR_BAR = 15                     # top-N orgs in bar plot\n",
    "HEATMAP_TOP_K = 20                     # top-K orgs in heatmap\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Stargazer style of output\n",
    "\n",
    "_STARGAZER_CSS = \"\"\"\n",
    "<style>\n",
    "/* Classic Stargazer-like table with box rules */\n",
    ".stgz { border-collapse: collapse; margin: 1.2rem 0; font-size: 14px; font-family: 'Times New Roman', Times, serif; }\n",
    ".stgz thead tr.rule-top    td, .stgz thead tr.rule-top    th { border-top: 2px solid #000; }\n",
    ".stgz tfoot tr.rule-bottom td, .stgz tfoot tr.rule-bottom th { border-bottom: 2px solid #000; }\n",
    ".stgz td, .stgz th { padding: 6px 10px; }\n",
    ".stgz .center { text-align: center; }\n",
    ".stgz .right  { text-align: right;  }\n",
    ".stgz .left   { text-align: left;   }\n",
    ".stgz .depvar { text-align: center; font-style: italic; }\n",
    ".stgz .note   { font-size: 12px; text-align: right; padding-top: 6px; }\n",
    ".stgz .hr { border-bottom: 1px solid #000; height: 0; }\n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "def _stars(p):\n",
    "    if p < 0.001: return \"***\"\n",
    "    if p < 0.01:  return \"**\"\n",
    "    if p < 0.05:  return \"*\"\n",
    "    return \"\"\n",
    "\n",
    "def _pseudo_r2(results):\n",
    "    # McFadden pseudo R^2 ~ 1 - (deviance/null_deviance)\n",
    "    try:\n",
    "        return max(0.0, 1.0 - (results.deviance / results.null_deviance))\n",
    "    except Exception:\n",
    "        try:\n",
    "            # fallback if available\n",
    "            return max(0.0, 1.0 - (results.llf / results.llnull))\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "\n",
    "def _escape(x): return html.escape(str(x))\n",
    "\n",
    "def render_stargazer(models, model_names, depvar_label, file_path, title=None):\n",
    "    \"\"\"\n",
    "    models: list of statsmodels Results (GLMResults)\n",
    "    model_names: list like [\"(M1)\",\"(M2)\",...]\n",
    "    depvar_label: e.g., \"Dependent variable: pred_normative\"\n",
    "    file_path: output HTML path\n",
    "    \"\"\"\n",
    "    # Collect full set of terms across models\n",
    "    all_terms = set()\n",
    "    for m in models:\n",
    "        all_terms |= set(m.params.index.tolist())\n",
    "    # Stargazer usually hides intercept text label; we keep \"Intercept\" row last\n",
    "    terms = [t for t in sorted(all_terms) if t != \"Intercept\"] + ([\"Intercept\"] if \"Intercept\" in all_terms else [])\n",
    "\n",
    "    # Build header rows\n",
    "    k = len(models)\n",
    "    header = []\n",
    "    header.append(f\"<tr class='rule-top'><th colspan='{k+1}'></th></tr>\")\n",
    "    if title:\n",
    "        header.append(f\"<tr><th colspan='{k+1}' class='center'>{_escape(title)}</th></tr>\")\n",
    "    header.append(f\"<tr><th colspan='{k+1}' class='depvar'>{_escape(depvar_label)}</th></tr>\")\n",
    "    # Model labels row\n",
    "    labels = \"\".join([f\"<th class='center'>{_escape(mn)}</th>\" for mn in model_names])\n",
    "    header.append(f\"<tr><th></th>{labels}</tr>\")\n",
    "    # small horizontal rule\n",
    "    header.append(f\"<tr><th colspan='{k+1}' class='hr'></th></tr>\")\n",
    "\n",
    "    # Body rows: for each term, show coef+stars, then SE row in parens\n",
    "    body = []\n",
    "    for term in terms:\n",
    "        row_coef = [f\"<td class='left'>{_escape(term)}</td>\"]\n",
    "        row_se   = [\"<td></td>\"]\n",
    "        for m in models:\n",
    "            if term in m.params.index:\n",
    "                coef = m.params[term]\n",
    "                se   = m.bse[term]\n",
    "                p    = m.pvalues[term]\n",
    "                row_coef.append(f\"<td class='center'>{coef:.3f}{_stars(p)}</td>\")\n",
    "                row_se.append(f\"<td class='center'>({_escape(f'{se:.3f}')})</td>\")\n",
    "            else:\n",
    "                row_coef.append(\"<td class='center'></td>\")\n",
    "                row_se.append(\"<td class='center'></td>\")\n",
    "        body.append(\"<tr>\" + \"\".join(row_coef) + \"</tr>\")\n",
    "        body.append(\"<tr>\" + \"\".join(row_se)   + \"</tr>\")\n",
    "\n",
    "    # Footer: Observations, Pseudo R^2\n",
    "    n_row = [\"<td class='left'>Observations</td>\"] + [f\"<td class='center'>{int(getattr(m,'nobs',np.nan))}</td>\" for m in models]\n",
    "    r2_row = [\"<td class='left'>Pseudo R<sup>2</sup></td>\"] + [f\"<td class='center'>{_pseudo_r2(m):.3f}</td>\" for m in models]\n",
    "\n",
    "    footer = []\n",
    "    footer.append(\"<tr><td colspan='999' class='hr'></td></tr>\")\n",
    "    footer.append(\"<tr>\" + \"\".join(n_row) + \"</tr>\")\n",
    "    footer.append(\"<tr>\" + \"\".join(r2_row) + \"</tr>\")\n",
    "    footer.append(\"<tr class='rule-bottom'><td colspan='999'></td></tr>\")\n",
    "    footer.append(\"<tr><td colspan='999' class='note'>* p&lt;0.05; ** p&lt;0.01; *** p&lt;0.001</td></tr>\")\n",
    "\n",
    "    table = \"<table class='stgz'>\" + \"\".join(header + body + footer) + \"</table>\"\n",
    "    html_doc = f\"<!DOCTYPE html><html><head><meta charset='utf-8'>{_STARGAZER_CSS}</head><body>{table}</body></html>\"\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html_doc)\n",
    "\n",
    "# helpers\n",
    "\n",
    "def cramers_v_from_chi2(chi2, n, r, k, bias_correct=True):\n",
    "    phi2 = chi2 / n\n",
    "    if bias_correct:\n",
    "        phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))\n",
    "        rcorr = r - ((r-1)**2)/(n-1)\n",
    "        kcorr = k - ((k-1)**2)/(n-1)\n",
    "        denom = min((kcorr-1), (rcorr-1))\n",
    "        return np.sqrt(phi2corr / denom) if denom > 0 else np.nan\n",
    "    else:\n",
    "        denom = min(k-1, r-1)\n",
    "        return np.sqrt(phi2 / denom) if denom > 0 else np.nan\n",
    "\n",
    "def odds_ratio_ci(table_2x2, alpha=0.05):\n",
    "    a,b = table_2x2[0]\n",
    "    c,d = table_2x2[1]\n",
    "    if 0 in [a,b,c,d]:\n",
    "        a,b,c,d = a+0.5, b+0.5, c+0.5, d+0.5\n",
    "    or_est = (a*d)/(b*c)\n",
    "    se = math.sqrt(1/a + 1/b + 1/c + 1/d)\n",
    "    z = stats.norm.ppf(1 - alpha/2)\n",
    "    lo, hi = math.exp(math.log(or_est) - z*se), math.exp(math.log(or_est) + z*se)\n",
    "    return or_est, lo, hi\n",
    "\n",
    "def add_or_table(results):\n",
    "    coefs = results.params.copy()\n",
    "    conf = results.conf_int()\n",
    "    out = pd.DataFrame({\n",
    "        \"coef\": coefs,\n",
    "        \"OR\": np.exp(coefs),\n",
    "        \"CI_low\": np.exp(conf[0]),\n",
    "        \"CI_high\": np.exp(conf[1]),\n",
    "        \"p\": results.pvalues\n",
    "    })\n",
    "    return out\n",
    "\n",
    "def make_decade(year):\n",
    "    try:\n",
    "        y = int(year)\n",
    "        return f\"{(y // 10) * 10}s\"\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "# load data\n",
    "\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    raise FileNotFoundError(f\"Could not find file at: {DATA_PATH}\")\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "expected_cols = {\"doc_id\",\"org\",\"year\",\"sent_id\",\"sentence\",\"pred_normative\"}\n",
    "missing = expected_cols - set(df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "df[\"pred_normative\"] = pd.to_numeric(df[\"pred_normative\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "df[\"year\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"year\", \"org\", \"doc_id\"])\n",
    "df[\"year\"] = df[\"year\"].astype(int)\n",
    "df[\"org\"] = df[\"org\"].astype(str).str.strip()\n",
    "df[\"doc_id\"] = df[\"doc_id\"].astype(str)\n",
    "df[\"decade\"] = df[\"year\"].apply(make_decade)\n",
    "df[\"pred_normative\"] = df[\"pred_normative\"].clip(0,1)\n",
    "\n",
    "# Descriptive stats\n",
    "\n",
    "overall_rate = df[\"pred_normative\"].mean()\n",
    "\n",
    "by_org = (df.groupby(\"org\")[\"pred_normative\"]\n",
    "            .agg(n=\"count\", norm_rate=\"mean\")\n",
    "            .sort_values(\"n\", ascending=False))\n",
    "by_org[\"norm_rate_pct\"] = 100*by_org[\"norm_rate\"]\n",
    "\n",
    "by_year = (df.groupby(\"year\")[\"pred_normative\"]\n",
    "             .agg(n=\"count\", norm_rate=\"mean\"))\n",
    "by_year[\"norm_rate_pct\"] = 100*by_year[\"norm_rate\"]\n",
    "\n",
    "# Save descriptive tables (same folder, simple HTML; these aren’t regression tables)\n",
    "def save_simple_table(df_in, path, title):\n",
    "    # light wrapper to keep style consistent with SG framing\n",
    "    cols = \"\".join([f\"<th>{_escape(c)}</th>\" for c in ([''] + df_in.columns.tolist())])\n",
    "    head = f\"<tr class='rule-top'><th colspan='{len(df_in.columns)+1}'></th></tr>\"\n",
    "    head += f\"<tr><th colspan='{len(df_in.columns)+1}' class='center'>{_escape(title)}</th></tr>\"\n",
    "    head += f\"<tr><th></th>{cols[4:]}</tr>\"\n",
    "    rows = []\n",
    "    for idx, row in df_in.iterrows():\n",
    "        rows.append(\"<tr>\" + f\"<td class='left'>{_escape(idx)}</td>\" +\n",
    "                    \"\".join([f\"<td class='right'>{_escape(v)}</td>\" for v in row]) + \"</tr>\")\n",
    "    foot = \"<tr class='rule-bottom'><td colspan='999'></td></tr>\"\n",
    "    html_doc = f\"<!DOCTYPE html><html><head><meta charset='utf-8'>{_STARGAZER_CSS}</head><body><table class='stgz'>{head}{''.join(rows)}{foot}</table></body></html>\"\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html_doc)\n",
    "\n",
    "overview = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        \"Total sentences\": [len(df)],\n",
    "        \"Total documents\": [df[\"doc_id\"].nunique()],\n",
    "        \"Total organizations\": [df[\"org\"].nunique()],\n",
    "        \"Year min\": [int(df[\"year\"].min())],\n",
    "        \"Year max\": [int(df[\"year\"].max())],\n",
    "        \"Overall normative share (%)\": [round(overall_rate*100.0, 2)]\n",
    "    }, orient=\"index\", columns=[\"Value\"]\n",
    ")\n",
    "save_simple_table(overview, os.path.join(OUTPUT_DIR, \"01_overview.html\"), \"Overview\")\n",
    "\n",
    "tmp2 = by_org.copy()\n",
    "tmp2[\"normative_share_%\"] = tmp2[\"norm_rate_pct\"].round(1)\n",
    "tmp2 = tmp2.drop(columns=[\"norm_rate\",\"norm_rate_pct\"])\n",
    "save_simple_table(tmp2, os.path.join(OUTPUT_DIR, \"02_by_organization.html\"), \"Normative vs Functional by Organization\")\n",
    "\n",
    "tmpy2 = by_year.copy()\n",
    "tmpy2[\"normative_share_%\"] = tmpy2[\"norm_rate_pct\"].round(1)\n",
    "tmpy2 = tmpy2.drop(columns=[\"norm_rate\",\"norm_rate_pct\"])\n",
    "save_simple_table(tmpy2, os.path.join(OUTPUT_DIR, \"03_by_year.html\"), \"Normative vs Functional by Year\")\n",
    "\n",
    "# Chi-sqr test\n",
    "\n",
    "org_counts = df[\"org\"].value_counts()\n",
    "keep_orgs = org_counts[org_counts >= MIN_COUNT_FOR_ORG_IN_CHISQ].index\n",
    "df_chi = df.copy()\n",
    "df_chi[\"org_pooled\"] = np.where(df_chi[\"org\"].isin(keep_orgs), df_chi[\"org\"], \"Other\")\n",
    "\n",
    "cont = pd.crosstab(df_chi[\"pred_normative\"], df_chi[\"org_pooled\"])\n",
    "\n",
    "if cont.size > 0 and cont.shape[1] >= 2:\n",
    "    chi2, p, dof, expected = stats.chi2_contingency(cont)\n",
    "    n = cont.to_numpy().sum()\n",
    "    cv = cramers_v_from_chi2(chi2, n, cont.shape[0], cont.shape[1], bias_correct=True)\n",
    "    chi_summary = pd.DataFrame.from_dict(\n",
    "        {\"chi2\":[chi2], \"dof\":[dof], \"p_value\":[p], \"Cramér_V\":[cv], \"N\":[int(n)],\n",
    "         \"cells exp<5\":[int((expected<5).sum())]}, orient=\"columns\")\n",
    "    save_simple_table(chi_summary.set_index(pd.Index([\"\"])), os.path.join(OUTPUT_DIR, \"04a_chi_square_summary.html\"),\n",
    "                      \"Chi-square: normative × org_pooled\")\n",
    "    save_simple_table(cont, os.path.join(OUTPUT_DIR, \"04b_chi_square_contingency.html\"),\n",
    "                      \"Contingency (rows=pred_normative, cols=org_pooled)\")\n",
    "    exp_df = pd.DataFrame(expected, index=cont.index, columns=cont.columns)\n",
    "    save_simple_table(exp_df, os.path.join(OUTPUT_DIR, \"04c_chi_square_expected.html\"),\n",
    "                      \"Expected Counts\")\n",
    "else:\n",
    "    save_simple_table(pd.DataFrame({\"note\":[\"Chi-square skipped (insufficient variation).\"]}).set_index(pd.Index([\"\"])),\n",
    "                      os.path.join(OUTPUT_DIR, \"04a_chi_square_summary.html\"),\n",
    "                      \"Chi-square: skipped\")\n",
    "\n",
    "# Pairwise Fisher (top-N orgs)\n",
    "top_orgs = org_counts.index[:TOP_N_FOR_FISHER]\n",
    "pairs = list(itertools.combinations(top_orgs, 2))\n",
    "fisher_rows = []\n",
    "for a,b in pairs:\n",
    "    sub = df[df[\"org\"].isin([a,b])]\n",
    "    tab = pd.crosstab(sub[\"org\"], sub[\"pred_normative\"]).reindex([a,b], fill_value=0)\n",
    "    if tab.shape[0] != 2:\n",
    "        continue\n",
    "    a_norm = tab.loc[a, 1] if 1 in tab.columns else 0\n",
    "    a_non  = tab.loc[a, 0] if 0 in tab.columns else 0\n",
    "    b_norm = tab.loc[b, 1] if 1 in tab.columns else 0\n",
    "    b_non  = tab.loc[b, 0] if 0 in tab.columns else 0\n",
    "    if (a_norm + a_non == 0) or (b_norm + b_non == 0):\n",
    "        continue\n",
    "    table = [[a_norm, a_non],[b_norm, b_non]]\n",
    "    oddsratio, pval = stats.fisher_exact(table, alternative='two-sided')\n",
    "    or_est, lo, hi = odds_ratio_ci(table)\n",
    "    fisher_rows.append({\n",
    "        \"org_A\": a, \"org_B\": b,\n",
    "        \"A_norm_rate_%\": (a_norm / max(1, (a_norm + a_non))) * 100.0,\n",
    "        \"B_norm_rate_%\": (b_norm / max(1, (b_norm + b_non))) * 100.0,\n",
    "        \"OR_A_vs_B\": or_est,\n",
    "        \"CI_low\": lo,\n",
    "        \"CI_high\": hi,\n",
    "        \"p_two_sided\": pval,\n",
    "        \"N\": a_norm + a_non + b_norm + b_non\n",
    "    })\n",
    "\n",
    "fisher_df = pd.DataFrame(fisher_rows)\n",
    "if not fisher_df.empty:\n",
    "    fisher_df[\"p_fdr\"] = multitest.multipletests(fisher_df[\"p_two_sided\"], method=\"fdr_bh\")[1]\n",
    "    fisher_df = fisher_df.sort_values(\"p_fdr\").reset_index(drop=True)\n",
    "    save_simple_table(fisher_df, os.path.join(OUTPUT_DIR, \"05_fisher_pairwise.html\"),\n",
    "                      \"Pairwise Fisher (Top-N orgs), FDR-corrected\")\n",
    "else:\n",
    "    save_simple_table(pd.DataFrame({\"note\":[\"Pairwise Fisher: no valid org pairs to test.\"]}).set_index(pd.Index([\"\"])),\n",
    "                      os.path.join(OUTPUT_DIR, \"05_fisher_pairwise.html\"),\n",
    "                      \"Pairwise Fisher: skipped\")\n",
    "\n",
    "# decade chi-square\n",
    "if df[\"decade\"].notna().any():\n",
    "    cont_dec = pd.crosstab(df[\"pred_normative\"], df[\"decade\"])\n",
    "    if cont_dec.size > 0 and cont_dec.shape[1] >= 2:\n",
    "        chi2d, pd_, dofd, expd = stats.chi2_contingency(cont_dec)\n",
    "        ndec = cont_dec.to_numpy().sum()\n",
    "        cvd = cramers_v_from_chi2(chi2d, ndec, cont_dec.shape[0], cont_dec.shape[1], bias_correct=True)\n",
    "        chi_dec = pd.DataFrame.from_dict(\n",
    "            {\"chi2\":[chi2d], \"dof\":[dofd], \"p_value\":[pd_], \"Cramér_V\":[cvd], \"N\":[int(ndec)]}, orient=\"columns\")\n",
    "        save_simple_table(chi_dec.set_index(pd.Index([\"\"])),\n",
    "                          os.path.join(OUTPUT_DIR, \"06_decade_chi_square_summary.html\"),\n",
    "                          \"Chi-square: normative × decade\")\n",
    "        save_simple_table(cont_dec, os.path.join(OUTPUT_DIR, \"06_decade_contingency.html\"),\n",
    "                          \"Contingency (rows=pred_normative, cols=decade)\")\n",
    "        expd_df = pd.DataFrame(expd, index=cont_dec.index, columns=cont_dec.columns)\n",
    "        save_simple_table(expd_df, os.path.join(OUTPUT_DIR, \"06_decade_expected.html\"),\n",
    "                          \"Expected Counts (decade)\")\n",
    "    else:\n",
    "        save_simple_table(pd.DataFrame({\"note\":[\"Decade chi-square skipped: insufficient variation.\"]}).set_index(pd.Index([\"\"])),\n",
    "                          os.path.join(OUTPUT_DIR, \"06_decade_chi_square_summary.html\"),\n",
    "                          \"Chi-square (decade): skipped\")\n",
    "\n",
    "# Log regression\n",
    "\n",
    "glm_m1 = smf.glm(\"pred_normative ~ year\",\n",
    "                 data=df,\n",
    "                 family=sm.families.Binomial())\n",
    "m1 = glm_m1.fit(cov_type=\"cluster\", cov_kwds={\"groups\": df[\"doc_id\"]})\n",
    "\n",
    "glm_m2 = smf.glm(\"pred_normative ~ year + C(org)\",\n",
    "                 data=df,\n",
    "                 family=sm.families.Binomial())\n",
    "m2 = glm_m2.fit(cov_type=\"cluster\", cov_kwds={\"groups\": df[\"doc_id\"]})\n",
    "\n",
    "render_stargazer(\n",
    "    models=[m1, m2],\n",
    "    model_names=[\"(M1)\",\"(M2)\"],\n",
    "    depvar_label=\"Dependent variable: pred_normative\",\n",
    "    file_path=os.path.join(OUTPUT_DIR, \"07_models_sentence_glm.html\"),\n",
    "    title=None\n",
    ")\n",
    "\n",
    "# OR table (nice-to-have, simple SG frame)\n",
    "m2_tbl = (add_or_table(m2)\n",
    "          .reset_index()\n",
    "          .rename(columns={\"index\":\"term\"}))\n",
    "m2_tbl[\"term\"] = (m2_tbl[\"term\"].str.replace(\"C(org)[T.\", \"org: \", regex=False)\n",
    "                               .str.replace(\"]\", \"\", regex=False))\n",
    "m2_tbl = m2_tbl.sort_values(\"p\")[[\"term\",\"OR\",\"CI_low\",\"CI_high\",\"p\"]]\n",
    "save_simple_table(m2_tbl.set_index(\"term\"),\n",
    "                  os.path.join(OUTPUT_DIR, \"08b_org_effects_or.html\"),\n",
    "                  \"Organization Effects (Odds Ratios, GLM with org FE)\")\n",
    "\n",
    "# Time series analysis\n",
    "\n",
    "agg_year = df.groupby(\"year\")[\"pred_normative\"].agg(y_sum=\"sum\", n=\"count\").reset_index()\n",
    "agg_year[\"rate\"] = agg_year[\"y_sum\"] / agg_year[\"n\"]\n",
    "\n",
    "if len(agg_year) >= 2:\n",
    "    # Use var_weights to avoid cov_type warning\n",
    "    glm1 = smf.glm(\"rate ~ year\",\n",
    "                   data=agg_year,\n",
    "                   family=sm.families.Binomial(),\n",
    "                   var_weights=agg_year[\"n\"])\n",
    "    ts1 = glm1.fit(cov_type=\"HAC\", cov_kwds={\"maxlags\":1})\n",
    "    render_stargazer(\n",
    "        models=[ts1],\n",
    "        model_names=[\"(M1)\"],\n",
    "        depvar_label=\"Dependent variable: rate (yearly normative share)\",\n",
    "        file_path=os.path.join(OUTPUT_DIR, \"09_glm_yearly_trend.html\"),\n",
    "        title=None\n",
    "    )\n",
    "else:\n",
    "    save_simple_table(pd.DataFrame({\"note\":[\"Year-level GLM skipped: < 2 years present.\"]}).set_index(pd.Index([\"\"])),\n",
    "                      os.path.join(OUTPUT_DIR, \"09_glm_yearly_trend.html\"),\n",
    "                      \"Year-level GLM: skipped\")\n",
    "\n",
    "panel = (df.groupby([\"org\",\"year\"])[\"pred_normative\"]\n",
    "           .agg(y_sum=\"sum\", n=\"count\").reset_index())\n",
    "panel[\"rate\"] = panel[\"y_sum\"]/panel[\"n\"]\n",
    "\n",
    "if not panel.empty and panel[\"org\"].nunique() >= 2:\n",
    "    glm2 = smf.glm(\"rate ~ year + C(org)\",\n",
    "                   data=panel,\n",
    "                   family=sm.families.Binomial(),\n",
    "                   var_weights=panel[\"n\"])\n",
    "    ts2 = glm2.fit(cov_type=\"cluster\", cov_kwds={\"groups\": panel[\"org\"]})\n",
    "    render_stargazer(\n",
    "        models=[ts2],\n",
    "        model_names=[\"(M1)\"],\n",
    "        depvar_label=\"Dependent variable: rate (org-year share)\",\n",
    "        file_path=os.path.join(OUTPUT_DIR, \"10_glm_org_year_panel.html\"),\n",
    "        title=None\n",
    "    )\n",
    "else:\n",
    "    save_simple_table(pd.DataFrame({\"note\":[\"Org-year GLM skipped: insufficient org/year variation.\"]}).set_index(pd.Index([\"\"])),\n",
    "                      os.path.join(OUTPUT_DIR, \"10_glm_org_year_panel.html\"),\n",
    "                      \"Org-year GLM: skipped\")\n",
    "\n",
    "# Visualisation\n",
    "\n",
    "plt.close(\"all\")\n",
    "\n",
    "# (A) Top orgs by volume with normative share\n",
    "top_org_plot = by_org.head(TOP_N_FOR_BAR).copy()\n",
    "if not top_org_plot.empty:\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    labels_rev = top_org_plot.index[::-1]\n",
    "    vals_rev = np.nan_to_num(top_org_plot[\"norm_rate\"].to_numpy()[::-1], nan=0.0)\n",
    "    bars = ax.barh(labels_rev, vals_rev)\n",
    "    ax.set_xlabel(\"Normative share\")\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.xaxis.set_major_formatter(PercentFormatter(1.0))\n",
    "    ax.set_title(f\"Normative share by organization (Top {len(top_org_plot)} by volume)\")\n",
    "    for b, val in zip(bars, vals_rev):\n",
    "        ax.text(min(val + 0.01, 0.98), b.get_y()+b.get_height()/2, f\"{val*100:.1f}%\", va=\"center\")\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(os.path.join(OUTPUT_DIR, \"11_plot_bar_by_org.png\"), dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "# (B) Time trend of normative rate (yearly)\n",
    "if not agg_year.empty:\n",
    "    fig, ax = plt.subplots(figsize=(10,5))\n",
    "    ax.plot(agg_year[\"year\"], agg_year[\"rate\"], marker=\"o\", linewidth=1.5)\n",
    "    ax.yaxis.set_major_formatter(PercentFormatter(1.0))\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.set_xlabel(\"Year\")\n",
    "    ax.set_ylabel(\"Normative share\")\n",
    "    ax.set_title(\"Yearly normative share over time\")\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(os.path.join(OUTPUT_DIR, \"12_plot_yearly_trend.png\"), dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "# (C) Heatmap: org (top K) x year normative rate\n",
    "heat_orgs = df[\"org\"].value_counts().head(HEATMAP_TOP_K).index\n",
    "heat = (df[df[\"org\"].isin(heat_orgs)]\n",
    "        .groupby([\"org\",\"year\"])[\"pred_normative\"]\n",
    "        .mean().unstack(\"year\"))\n",
    "\n",
    "if (heat.shape[0] > 0) and (heat.shape[1] > 0):\n",
    "    fig, ax = plt.subplots(figsize=(12, max(6, 0.45*heat.shape[0])))\n",
    "    im = ax.imshow(heat.values, aspect=\"auto\", interpolation=\"nearest\")\n",
    "    im.set_clim(0, 1)\n",
    "    ax.set_yticks(range(len(heat.index)))\n",
    "    ax.set_yticklabels(heat.index)\n",
    "    ax.set_xticks(range(len(heat.columns)))\n",
    "    ax.set_xticklabels(heat.columns, rotation=90)\n",
    "    ax.set_title(f\"Normative share heatmap (Top {len(heat_orgs)} orgs by volume)\")\n",
    "    cbar = plt.colorbar(im, ax=ax, fraction=0.02, pad=0.02)\n",
    "    cbar.ax.yaxis.set_major_formatter(PercentFormatter(1.0))\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(os.path.join(OUTPUT_DIR, \"13_plot_heatmap_org_year.png\"), dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "# (D) Coefficient display: year effect + some org effects from Model 2\n",
    "try:\n",
    "    coef_df = add_or_table(m2).reset_index().rename(columns={\"index\":\"term\"})\n",
    "    coef_df[\"is_org\"] = coef_df[\"term\"].str.startswith(\"C(org)\")\n",
    "    big_org_terms = [\"C(org)[T.\" + o + \"]\" for o in df[\"org\"].value_counts().index[:10] if \"C(org)[T.\" + o + \"]\" in set(coef_df[\"term\"])]\n",
    "    plot_terms = ([\"year\"] if \"year\" in coef_df[\"term\"].values else []) + big_org_terms\n",
    "    plot_subset = coef_df[coef_df[\"term\"].isin(plot_terms)].copy()\n",
    "    if not plot_subset.empty:\n",
    "        if \"year\" in plot_subset[\"term\"].values:\n",
    "            plot_subset = pd.concat([\n",
    "                plot_subset[plot_subset[\"term\"]==\"year\"],\n",
    "                plot_subset[(plot_subset[\"term\"]!=\"year\")].sort_values(\"OR\", ascending=False)\n",
    "            ])\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        ypos = np.arange(len(plot_subset))\n",
    "        x = plot_subset[\"OR\"].to_numpy()\n",
    "        lo = plot_subset[\"CI_low\"].to_numpy()\n",
    "        hi = plot_subset[\"CI_high\"].to_numpy()\n",
    "        ax.errorbar(x, ypos, xerr=[x - lo, hi - x], fmt='o', capsize=3)\n",
    "        ax.axvline(1.0, linewidth=1)\n",
    "        ax.set_yticks(ypos)\n",
    "        pretty_labels = plot_subset[\"term\"].str.replace(\"C(org)[T.\", \"org: \", regex=False).str.replace(\"]\", \"\", regex=False).tolist()\n",
    "        ax.set_yticklabels(pretty_labels)\n",
    "        ax.set_xlabel(\"Odds Ratio (GLM Binomial with org FE)\")\n",
    "        ax.set_title(\"Selected effects with 95% CIs\")\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(os.path.join(OUTPUT_DIR, \"14_plot_coef.png\"), dpi=200)\n",
    "        plt.close(fig)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIR, \"00_run_log.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"Run completed.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a363523d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
